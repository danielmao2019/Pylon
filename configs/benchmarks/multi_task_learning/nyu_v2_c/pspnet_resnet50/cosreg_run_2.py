# This file is automatically generated by `./configs/benchmarks/multi_task_learning/gen_multi_task_learning.py`.
# Please do not attempt to modify manually.
import torch
import schedulers


config = {
    'runner': None,
    'work_dir': None,
    'epochs': 100,
    # seeds
    'init_seed': None,
    'train_seeds': None,
    'val_seeds': None,
    'test_seed': None,
    # dataset config
    'train_dataset': None,
    'train_dataloader': None,
    'val_dataset': None,
    'val_dataloader': None,
    'test_dataset': None,
    'test_dataloader': None,
    'criterion': None,
    'metric': None,
    # model config
    'model': None,
    # optimizer config
    'optimizer': None,
    'scheduler': {
        'class': torch.optim.lr_scheduler.LambdaLR,
        'args': {
            'lr_lambda': {
                'class': schedulers.lr_lambdas.WarmupLambda,
                'args': {},
            },
        },
    },
}

from runners import SupervisedMultiTaskTrainer
config['runner'] = SupervisedMultiTaskTrainer

# dataset config
from configs.common.datasets.multi_task_learning.nyu_v2_c import config as dataset_config
config.update(dataset_config)

# model config
from configs.common.models.multi_task_learning.nyu_v2_c.pspnet_resnet50 import model_config_all_tasks as model_config
config['model'] = model_config

# optimizer config
from configs.common.optimizers.multi_task_learning.cosreg import optimizer_config
from configs.common.optimizers.standard import adam_optimizer_config
optimizer_config['args']['optimizer_config'] = adam_optimizer_config
optimizer_config['args']['per_layer'] = False
config['optimizer'] = optimizer_config

# seeds
config['init_seed'] = 34489378
config['train_seeds'] = [45936228, 59516586, 51968525, 7373002, 59406888, 54273462, 78132142, 41126891, 47272930, 71521414, 67113171, 63805594, 52869904, 17690809, 92015246, 34044797, 80790132, 31474109, 93222910, 594469, 27754190, 27641042, 88232532, 29764997, 26746660, 81764586, 28383656, 52602197, 30606163, 77724605, 32027589, 83460080, 25540482, 23024718, 33873277, 82791238, 20918124, 7979453, 4904750, 82990950, 81487838, 14651482, 865796, 56255091, 83565908, 42933497, 71761615, 80174232, 4854399, 88897006, 76502217, 51804825, 90031296, 29411952, 44002768, 873687, 73709717, 7000841, 12744956, 26839576, 6835491, 80063476, 10398, 72554390, 65321052, 85618062, 80245955, 94625652, 93449375, 78399241, 68917000, 49036576, 46212635, 22601874, 98864584, 31976141, 68198614, 29636992, 5627720, 80766253, 18259123, 51700456, 25434506, 18027353, 61412434, 62732274, 94285284, 73079280, 59412382, 4615894, 42729700, 51660525, 8516412, 45785890, 68425996, 61659103, 23513452, 78231173, 98732629, 78301602]
config['val_seeds'] = [35733491, 69353771, 56948216, 48674506, 10514978, 24128275, 25801087, 52476915, 87167182, 19864435, 76552302, 9958504, 60568231, 31853622, 12643441, 64988659, 89799584, 10114056, 67783059, 86021580, 5449922, 43495487, 2531150, 99382343, 77074183, 32909912, 48145583, 22983287, 51052598, 5818677, 56303147, 90785962, 95844834, 64048403, 92577493, 67506291, 83989906, 22193402, 5828851, 68185001, 79541746, 69130169, 32272524, 13017662, 74441782, 86326777, 55542610, 16452023, 29692043, 10995402, 11017167, 3330602, 60479124, 3916270, 70024900, 66345619, 50299175, 8882035, 48102635, 80035395, 76798314, 54857864, 98944977, 72914561, 20503264, 44358196, 20750063, 28442714, 75448804, 72300880, 56243488, 11271725, 32566387, 95099692, 62003566, 40777810, 72302875, 36886233, 77441870, 26508491, 34163661, 78412337, 93338299, 99937227, 35702948, 46343265, 57801666, 95933036, 5777138, 30303629, 34619871, 89502842, 61840786, 88178057, 71080216, 76916359, 18368469, 51078427, 24761862, 24309933]
config['test_seed'] = 30024605

# work dir
config['work_dir'] = "./logs/benchmarks/multi_task_learning/nyu_v2_c/pspnet_resnet50/cosreg_run_2"
