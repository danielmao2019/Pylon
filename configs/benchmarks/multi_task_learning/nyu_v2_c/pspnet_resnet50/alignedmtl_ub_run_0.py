# This file is automatically generated by `./configs/benchmarks/multi_task_learning/gen_multi_task_learning.py`.
# Please do not attempt to modify manually.
import torch
import schedulers


config = {
    'runner': None,
    'work_dir': None,
    'epochs': 100,
    # seeds
    'init_seed': None,
    'train_seeds': None,
    'val_seeds': None,
    'test_seed': None,
    # dataset config
    'train_dataset': None,
    'train_dataloader': None,
    'val_dataset': None,
    'val_dataloader': None,
    'test_dataset': None,
    'test_dataloader': None,
    'criterion': None,
    'metric': None,
    # model config
    'model': None,
    # optimizer config
    'optimizer': None,
    'scheduler': {
        'class': torch.optim.lr_scheduler.LambdaLR,
        'args': {
            'lr_lambda': {
                'class': schedulers.lr_lambdas.WarmupLambda,
                'args': {},
            },
        },
    },
}

from runners import SupervisedMultiTaskTrainer
config['runner'] = SupervisedMultiTaskTrainer

# dataset config
from configs.common.datasets.multi_task_learning.nyu_v2_c import config as dataset_config
config.update(dataset_config)

# model config
from configs.common.models.multi_task_learning.nyu_v2_c.pspnet_resnet50 import model_config_all_tasks as model_config
config['model'] = model_config

# optimizer config
from configs.common.optimizers.multi_task_learning.alignedmtl_ub import optimizer_config
from configs.common.optimizers.standard import adam_optimizer_config
optimizer_config['args']['optimizer_config'] = adam_optimizer_config
optimizer_config['args']['per_layer'] = False
config['optimizer'] = optimizer_config

# seeds
config['init_seed'] = 40166136
config['train_seeds'] = [51574716, 16551297, 8474190, 92845968, 82005460, 53028259, 12607976, 20168648, 29005798, 22176896, 8291183, 8219565, 30998618, 8895837, 42021576, 61754186, 36918522, 90916546, 79797089, 96070036, 58753711, 4268020, 6008110, 81447760, 96006563, 15122083, 10008466, 93922847, 54627531, 1079198, 5722241, 82051104, 7484173, 32048476, 39111192, 86055967, 19963079, 20928548, 80973291, 51220816, 55106830, 61489792, 77143738, 32607049, 98066756, 70087847, 84022632, 12364998, 52096412, 9835152, 14535167, 90639693, 53768502, 9152346, 93885519, 10589665, 81776035, 74594910, 3386340, 34373711, 11546422, 62564218, 42602583, 86485189, 99497123, 37005095, 19907442, 92785682, 63291665, 94983529, 58753954, 81734264, 82584693, 45755111, 13457836, 62430865, 40721189, 66611755, 22734299, 25384639, 97486912, 28775362, 5067519, 8822786, 6178657, 97698252, 56978450, 9355088, 46798326, 92122661, 60510253, 77159131, 62018182, 31494788, 9409970, 94388791, 90020182, 88355875, 74557674, 63419147]
config['val_seeds'] = [54453143, 49923864, 45280269, 43377342, 78359034, 12244610, 95640667, 94582803, 9951488, 11391039, 4109282, 26653186, 83660909, 28186488, 44326695, 69705581, 10949968, 13655682, 38863669, 13777659, 22375456, 52703880, 28609492, 3335556, 7393032, 46002004, 24006932, 86970306, 79173229, 33766112, 17684668, 70323401, 13756948, 44847668, 93740477, 97563050, 11889598, 88848182, 51804232, 8679394, 77782222, 81176258, 84669194, 22236213, 5346579, 32623158, 35502006, 32507510, 54700611, 74612089, 83950220, 27247218, 75378053, 83005080, 44399490, 3550320, 89165440, 24688851, 36804063, 63636771, 70578573, 58285958, 35797899, 63257209, 88707580, 65570341, 71018555, 65887554, 79147614, 3586868, 66189249, 87244878, 14017046, 90273454, 91509288, 65470987, 91492037, 59821360, 94131313, 97776619, 2749649, 65017539, 33827391, 67157117, 3311743, 13341371, 40404254, 484898, 41138574, 29051443, 18287875, 30354968, 68413251, 12483883, 23765577, 48196662, 58258126, 87066496, 97836780, 10696256]
config['test_seed'] = 43616764

# work dir
config['work_dir'] = "./logs/benchmarks/multi_task_learning/nyu_v2_c/pspnet_resnet50/alignedmtl_ub_run_0"
