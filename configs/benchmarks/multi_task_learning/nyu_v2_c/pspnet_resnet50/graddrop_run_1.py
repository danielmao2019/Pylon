# This file is automatically generated by `./configs/benchmarks/multi_task_learning/gen_multi_task_learning.py`.
# Please do not attempt to modify manually.
import torch
import schedulers


config = {
    'runner': None,
    'work_dir': None,
    'epochs': 100,
    # seeds
    'init_seed': None,
    'train_seeds': None,
    'val_seeds': None,
    'test_seed': None,
    # dataset config
    'train_dataset': None,
    'train_dataloader': None,
    'val_dataset': None,
    'val_dataloader': None,
    'test_dataset': None,
    'test_dataloader': None,
    'criterion': None,
    'metric': None,
    # model config
    'model': None,
    # optimizer config
    'optimizer': None,
    'scheduler': {
        'class': torch.optim.lr_scheduler.LambdaLR,
        'args': {
            'lr_lambda': {
                'class': schedulers.lr_lambdas.WarmupLambda,
                'args': {},
            },
        },
    },
}

from runners import SupervisedMultiTaskTrainer
config['runner'] = SupervisedMultiTaskTrainer

# dataset config
from configs.common.datasets.multi_task_learning.nyu_v2_c import config as dataset_config
config.update(dataset_config)

# model config
from configs.common.models.multi_task_learning.nyu_v2_c.pspnet_resnet50 import model_config_all_tasks as model_config
config['model'] = model_config

# optimizer config
from configs.common.optimizers.multi_task_learning.graddrop import optimizer_config
from configs.common.optimizers.standard import adam_optimizer_config
optimizer_config['args']['optimizer_config'] = adam_optimizer_config
optimizer_config['args']['per_layer'] = False
config['optimizer'] = optimizer_config

# seeds
config['init_seed'] = 67564380
config['train_seeds'] = [96640803, 8045189, 6922495, 72217482, 69054168, 74544483, 22649950, 6441710, 66474639, 98214739, 38702883, 79803846, 29436467, 8706307, 68571533, 56625443, 3048895, 6589997, 75554692, 73305497, 32827331, 60032700, 68379065, 56995458, 69671013, 90863118, 82684539, 59603507, 56107043, 50090971, 98472565, 5025383, 15854162, 32121691, 23164167, 89779596, 58157033, 17831459, 31010692, 84540413, 30202628, 26293330, 5521858, 93766502, 49162483, 66788331, 58426762, 93746645, 77746034, 8450247, 8792585, 48871164, 21969832, 48436429, 9433305, 73952310, 55346844, 7765281, 76425326, 83538377, 26764257, 91746638, 20863782, 8589064, 28487153, 38211141, 52779174, 69968221, 80327083, 60814408, 55204834, 51024906, 85702212, 80944440, 65865139, 56388587, 15560623, 33081909, 97105427, 37291319, 25370017, 4017400, 76607701, 98515034, 29085141, 57239481, 53237615, 41831738, 30090049, 33841125, 29215692, 30372480, 41299869, 28267078, 5762504, 89000443, 88414466, 45461683, 18343335, 2951576]
config['val_seeds'] = [55877992, 59008782, 21175885, 16700911, 56918588, 93818543, 71073892, 23423982, 21545356, 87718911, 51256701, 76641369, 25030502, 60374812, 33285638, 47758679, 37742610, 66581690, 1254375, 71849064, 63323255, 228599, 10218585, 92464027, 83561058, 42103809, 67791985, 67252985, 6797386, 92264486, 98047249, 23594646, 24140978, 60481524, 25351361, 53503304, 78281867, 75239287, 35213188, 1055178, 22467345, 18529181, 48298392, 93018589, 57325712, 64080079, 44959162, 4834067, 78662720, 3797983, 59479350, 94641980, 439254, 1052371, 79323525, 98483009, 48677323, 32585736, 12309816, 47716992, 328028, 10714067, 73981794, 37912531, 67638456, 98237526, 46062261, 39131778, 31592928, 47555507, 57332779, 71556641, 62481919, 7574869, 83164923, 28008796, 72186963, 15250737, 37454986, 1842462, 74185911, 43943695, 77896056, 80025119, 12027358, 7471627, 79052530, 69960148, 73337516, 30930851, 50707848, 65205862, 30740869, 66556835, 48313852, 5921821, 1101242, 45545741, 88510762, 96598020]
config['test_seed'] = 30042888

# work dir
config['work_dir'] = "./logs/benchmarks/multi_task_learning/nyu_v2_c/pspnet_resnet50/graddrop_run_1"
