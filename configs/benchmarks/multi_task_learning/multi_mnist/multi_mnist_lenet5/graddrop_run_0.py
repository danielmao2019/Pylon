# This file is automatically generated by `./configs/benchmarks/multi_task_learning/gen_multi_task_learning.py`.
# Please do not attempt to modify manually.
import torch
import schedulers


config = {
    'runner': None,
    'work_dir': None,
    'epochs': 100,
    # seeds
    'init_seed': None,
    'train_seeds': None,
    # dataset config
    'train_dataset': None,
    'train_dataloader': None,
    'val_dataset': None,
    'val_dataloader': None,
    'test_dataset': None,
    'test_dataloader': None,
    'criterion': None,
    'metric': None,
    # model config
    'model': None,
    # optimizer config
    'optimizer': None,
    'scheduler': {
        'class': torch.optim.lr_scheduler.LambdaLR,
        'args': {
            'lr_lambda': {
                'class': schedulers.WarmupLambda,
                'args': {},
            },
        },
    },
}

from runners import SupervisedMultiTaskTrainer
config['runner'] = SupervisedMultiTaskTrainer

# dataset config
from configs.common.datasets.multi_task_learning.multi_mnist import config as dataset_config
config.update(dataset_config)

# model config
from configs.common.models.multi_task_learning.multi_mnist.multi_mnist_lenet5 import model_config_all_tasks as model_config
config['model'] = model_config

# optimizer config
from configs.common.optimizers.multi_task_learning.graddrop import optimizer_config
from configs.common.optimizers.standard import adam_optimizer_config
optimizer_config['args']['optimizer_config'] = adam_optimizer_config
optimizer_config['args']['per_layer'] = False
config['optimizer'] = optimizer_config

# seeds
config['init_seed'] = 59769072
config['train_seeds'] = [30862157, 64027670, 60105508, 63032441, 47435904, 80365802, 20244501, 16779066, 25511962, 46574133, 1227794, 60879876, 48824128, 5183461, 85873670, 69912221, 67245978, 40397487, 9989411, 88129781, 33847490, 22973525, 7454693, 35540897, 86666473, 5309743, 50436074, 72917088, 531253, 39370427, 73225468, 42756968, 34013632, 88667516, 73165965, 43219734, 74334350, 47131112, 20973756, 80835703, 64500227, 39865859, 32665260, 89345193, 16849480, 84519774, 61549319, 98300750, 77679466, 38212207, 17448806, 9890974, 15533607, 81964273, 51606492, 33405277, 91863457, 21643516, 35527977, 1135264, 59938800, 70593669, 92425520, 47202410, 19061788, 9092531, 63874128, 78254064, 58980739, 29866790, 9014119, 4651231, 28894489, 15439078, 62165057, 68228396, 5565120, 61925865, 56866139, 91637903, 35923534, 70820954, 28203493, 40707711, 10910933, 48113347, 36879560, 81627967, 80771292, 42703092, 31192277, 6383342, 85627239, 94896907, 97566151, 61362422, 56729876, 98492665, 51054957, 66262826]

# work dir
config['work_dir'] = "./logs/benchmarks/multi_task_learning/multi_mnist/multi_mnist_lenet5/graddrop_run_0"
