# This file is automatically generated by `./configs/benchmarks/multi_task_learning/gen_multi_task_learning.py`.
# Please do not attempt to modify manually.
import torch
import schedulers


config = {
    'runner': None,
    'work_dir': None,
    'epochs': 100,
    # seeds
    'init_seed': None,
    'train_seeds': None,
    'val_seeds': None,
    'test_seed': None,
    # dataset config
    'train_dataset': None,
    'train_dataloader': None,
    'val_dataset': None,
    'val_dataloader': None,
    'test_dataset': None,
    'test_dataloader': None,
    'criterion': None,
    'metric': None,
    # model config
    'model': None,
    # optimizer config
    'optimizer': None,
    'scheduler': {
        'class': torch.optim.lr_scheduler.LambdaLR,
        'args': {
            'lr_lambda': {
                'class': schedulers.lr_lambdas.WarmupLambda,
                'args': {},
            },
        },
    },
}

from runners import SupervisedMultiTaskTrainer
config['runner'] = SupervisedMultiTaskTrainer

# dataset config
from configs.common.datasets.multi_task_learning.multi_mnist import config as dataset_config
config.update(dataset_config)

# model config
from configs.common.models.multi_task_learning.multi_mnist.multi_mnist_lenet5 import model_config_all_tasks as model_config
config['model'] = model_config

# optimizer config
from configs.common.optimizers.multi_task_learning.alignedmtl import optimizer_config
from configs.common.optimizers.standard import adam_optimizer_config
optimizer_config['args']['optimizer_config'] = adam_optimizer_config
optimizer_config['args']['per_layer'] = False
config['optimizer'] = optimizer_config

# seeds
config['init_seed'] = 27317973
config['train_seeds'] = [26181209, 14955943, 81255950, 55846020, 40316383, 86919375, 29399893, 59443153, 81923267, 18918746, 62386928, 13683443, 98790129, 71495371, 5483981, 66274972, 25218241, 25519138, 86973960, 19818312, 7914240, 90386418, 35900811, 29674609, 87469976, 65623857, 3612360, 58281123, 51835813, 24919146, 30263253, 54285147, 47892243, 15257024, 30852404, 21952472, 63880180, 48780078, 1308467, 77124565, 5517843, 97269701, 69480587, 83200129, 81849368, 23049694, 95661793, 81810806, 27406592, 70667440, 64593385, 15019218, 67591047, 79255976, 69748158, 15439275, 74310179, 45280493, 11779329, 16188073, 89365693, 4873914, 55535055, 56174188, 45085908, 52473759, 12126351, 99643143, 2644153, 40458519, 45296175, 81080378, 58364554, 41055369, 98460898, 57290388, 63069468, 29895024, 67579178, 66271336, 29128430, 43256739, 17957235, 65516044, 74564353, 56648117, 15319363, 83897171, 33269939, 38013001, 251376, 67003518, 58346161, 81286488, 52663094, 27688959, 71327706, 27212254, 70710454, 33078340]
config['val_seeds'] = [30020252, 3811010, 74850676, 97675889, 84553840, 65173135, 5599565, 10780484, 94602224, 13630541, 32561044, 4285089, 57240025, 75902857, 20363847, 45934786, 61198335, 68383667, 54765382, 1742366, 38490576, 39325754, 78869405, 95681554, 14865683, 60107625, 47631186, 21496158, 63898944, 78102231, 74402864, 95973958, 9996366, 57929276, 59758378, 74569552, 83583785, 50004842, 96155724, 5535803, 69081487, 5079215, 13274802, 29184534, 78737763, 62799994, 57515084, 88074494, 48356208, 74186748, 73957981, 74150304, 57064643, 68455496, 64539123, 1588825, 95318945, 1688036, 17038226, 94341463, 49386214, 5888221, 43934231, 65564780, 71719061, 30860701, 3127039, 9380922, 87681943, 22541130, 47979162, 20124474, 10145707, 20067176, 2213058, 15654101, 73177682, 95186300, 61784463, 64455007, 30837884, 2874792, 23383567, 38340133, 73092876, 51724691, 84938439, 21221380, 15622418, 96287665, 22743527, 21652361, 74191584, 97670721, 30434880, 51508223, 31572449, 95586966, 71155742, 1251105]
config['test_seed'] = 25595963

# work dir
config['work_dir'] = "./logs/benchmarks/multi_task_learning/multi_mnist/multi_mnist_lenet5/alignedmtl_run_2"
