# This file is automatically generated by `./configs/benchmarks/multi_task_learning/gen_multi_task_learning.py`.
# Please do not attempt to modify manually.
import torch
import schedulers


config = {
    'runner': None,
    'work_dir': None,
    'epochs': 100,
    # seeds
    'init_seed': None,
    'train_seeds': None,
    'val_seeds': None,
    'test_seed': None,
    # dataset config
    'train_dataset': None,
    'train_dataloader': None,
    'val_dataset': None,
    'val_dataloader': None,
    'test_dataset': None,
    'test_dataloader': None,
    'criterion': None,
    'metric': None,
    # model config
    'model': None,
    # optimizer config
    'optimizer': None,
    'scheduler': {
        'class': torch.optim.lr_scheduler.LambdaLR,
        'args': {
            'lr_lambda': {
                'class': schedulers.lr_lambdas.WarmupLambda,
                'args': {},
            },
        },
    },
}

from runners import SupervisedMultiTaskTrainer
config['runner'] = SupervisedMultiTaskTrainer

# dataset config
from configs.common.datasets.multi_task_learning.multi_mnist import config as dataset_config
config.update(dataset_config)

# model config
from configs.common.models.multi_task_learning.multi_mnist.multi_mnist_lenet5 import model_config_all_tasks as model_config
config['model'] = model_config

# optimizer config
from configs.common.optimizers.multi_task_learning.gradvac import optimizer_config
from configs.common.optimizers.standard import adam_optimizer_config
optimizer_config['args']['optimizer_config'] = adam_optimizer_config
optimizer_config['args']['per_layer'] = False
config['optimizer'] = optimizer_config

# seeds
config['init_seed'] = 55754036
config['train_seeds'] = [47886958, 45629022, 15157202, 14052121, 67203732, 42237262, 82496474, 66505270, 73108067, 36844987, 20374381, 74595562, 93335171, 94515836, 58065293, 49875227, 91910402, 87120410, 22495834, 4225290, 21088445, 91231632, 80252838, 16217069, 9873430, 26575161, 73887577, 10123247, 25596126, 85505262, 58662717, 35582386, 6200497, 29793535, 79569835, 83662866, 5760497, 29966451, 47986141, 60081077, 74250807, 65278441, 3118475, 44268904, 10181578, 44593929, 80588767, 66959506, 71833569, 39397878, 30852406, 67768489, 88441346, 38649679, 1161337, 61073163, 1615096, 28538982, 65411633, 76291016, 96979694, 695941, 29750269, 95490101, 47768015, 86163125, 89501774, 18698049, 71907596, 15421831, 68127985, 61602531, 570714, 9676631, 26470623, 3479441, 97402945, 99012102, 48974671, 1076404, 82471756, 2425199, 93750558, 5585970, 89432248, 15640395, 84672568, 57642541, 13918373, 8703947, 15767214, 24129418, 62301652, 15295738, 45426981, 11020795, 58001216, 45512748, 63555887, 39210252]
config['val_seeds'] = [43191080, 76054497, 31314694, 3948812, 74705080, 84603277, 23457960, 23261598, 75905513, 41033955, 19310772, 87424833, 68948753, 95244160, 46399169, 1630570, 56163421, 85852350, 59619038, 66237013, 22715453, 55831063, 35575070, 32852097, 79478617, 94164997, 27680680, 4889421, 22079781, 72194724, 59461440, 17328275, 8753396, 25428734, 83830909, 29872295, 50651579, 3505409, 78242407, 21583629, 97507673, 55677602, 86626137, 86917016, 58081209, 3365924, 62733504, 52698576, 13076321, 41101029, 59777137, 37195122, 90061095, 68318491, 20879266, 21008230, 73152472, 48034942, 20390060, 23562477, 49439693, 57741621, 96366678, 93488775, 49570896, 5317468, 18502649, 35739691, 29564854, 23653097, 93094752, 37857271, 60496175, 67245151, 92458460, 17681600, 7262261, 67350370, 50643085, 33377828, 671625, 57994056, 62647094, 37242103, 91246335, 34092985, 19369118, 46011791, 87438418, 75640315, 62328845, 67345923, 87685678, 95890641, 26268712, 78273913, 19606123, 17632072, 54599203, 48735536]
config['test_seed'] = 7402228

# work dir
config['work_dir'] = "./logs/benchmarks/multi_task_learning/multi_mnist/multi_mnist_lenet5/gradvac_run_0"
