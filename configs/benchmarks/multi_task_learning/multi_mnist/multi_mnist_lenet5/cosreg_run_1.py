# This file is automatically generated by `./configs/benchmarks/multi_task_learning/gen_multi_task_learning.py`.
# Please do not attempt to modify manually.
import torch
import schedulers


config = {
    'runner': None,
    'work_dir': None,
    'epochs': 100,
    # seeds
    'init_seed': None,
    'train_seeds': None,
    'val_seeds': None,
    'test_seed': None,
    # dataset config
    'train_dataset': None,
    'train_dataloader': None,
    'val_dataset': None,
    'val_dataloader': None,
    'test_dataset': None,
    'test_dataloader': None,
    'criterion': None,
    'metric': None,
    # model config
    'model': None,
    # optimizer config
    'optimizer': None,
    'scheduler': {
        'class': torch.optim.lr_scheduler.LambdaLR,
        'args': {
            'lr_lambda': {
                'class': schedulers.lr_lambdas.WarmupLambda,
                'args': {},
            },
        },
    },
}

from runners import SupervisedMultiTaskTrainer
config['runner'] = SupervisedMultiTaskTrainer

# dataset config
from configs.common.datasets.multi_task_learning.multi_mnist import config as dataset_config
config.update(dataset_config)

# model config
from configs.common.models.multi_task_learning.multi_mnist.multi_mnist_lenet5 import model_config_all_tasks as model_config
config['model'] = model_config

# optimizer config
from configs.common.optimizers.multi_task_learning.cosreg import optimizer_config
from configs.common.optimizers.standard import adam_optimizer_config
optimizer_config['args']['optimizer_config'] = adam_optimizer_config
optimizer_config['args']['per_layer'] = False
config['optimizer'] = optimizer_config

# seeds
config['init_seed'] = 85354392
config['train_seeds'] = [55972129, 54867276, 91590348, 73164707, 99987370, 50524483, 10116020, 31765031, 69279915, 85294447, 39917945, 65680639, 66929766, 22721927, 14304953, 44362061, 93474004, 16928769, 82682263, 40010786, 29032454, 62000750, 50094748, 36412775, 62842711, 63594394, 50413601, 94149409, 60282489, 71380042, 46326679, 44019157, 1020772, 10963975, 3718950, 20412485, 86276347, 90686185, 58364612, 51682581, 51013318, 30802523, 69817506, 40549877, 87939745, 73006774, 76852108, 34051186, 94627071, 25598594, 79334787, 47738957, 50910424, 29343431, 70296756, 63660749, 71851200, 20034149, 16652149, 28216639, 11235, 44287823, 5689748, 12617552, 13098008, 86020708, 74810304, 49914334, 29093797, 90116859, 54861595, 88498067, 29889314, 4846510, 39664883, 98575393, 30712365, 51281545, 3682777, 61824020, 79794597, 66539023, 86770252, 83002018, 41895896, 91884989, 89114984, 98110147, 40956366, 43348501, 8221758, 38008946, 66660201, 94640429, 56979569, 71347745, 82443797, 35486534, 93779190, 51644671]
config['val_seeds'] = [18711857, 75857544, 17432580, 96072601, 31365279, 52160996, 24848790, 50527153, 30267494, 64702462, 80794854, 29131742, 35345911, 76694722, 71858503, 47182267, 93943063, 78677617, 36294830, 16776070, 38248006, 72086254, 77512158, 76694995, 26988303, 46796374, 91231082, 44415576, 21848187, 5347779, 23751836, 33284683, 45434709, 63803329, 64674912, 29530780, 36844392, 19491866, 8869265, 3700662, 60277020, 13811137, 80837928, 95914874, 42196206, 2909873, 52867252, 41709465, 83384375, 5003986, 35852253, 54063032, 91235231, 26822437, 56679483, 47732758, 52052856, 50006189, 77301974, 80144879, 54426613, 81719662, 14737190, 27198364, 41547296, 89109102, 51641793, 53543093, 5266850, 25126360, 39463273, 88947132, 33460764, 69796708, 74030937, 58450502, 7079, 88394105, 36246969, 70884069, 91891294, 42946518, 68785167, 79336422, 25985901, 29088365, 11348503, 46350459, 56957028, 65732770, 20207000, 86610797, 52326235, 11183446, 22370787, 92501017, 32276877, 97144496, 88799994, 89997638]
config['test_seed'] = 57140199

# work dir
config['work_dir'] = "./logs/benchmarks/multi_task_learning/multi_mnist/multi_mnist_lenet5/cosreg_run_1"
