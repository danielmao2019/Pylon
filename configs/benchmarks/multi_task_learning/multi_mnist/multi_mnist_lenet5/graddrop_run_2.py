# This file is automatically generated by `./configs/benchmarks/multi_task_learning/gen_multi_task_learning.py`.
# Please do not attempt to modify manually.
import torch
import schedulers


config = {
    'runner': None,
    'work_dir': None,
    'epochs': 100,
    # seeds
    'init_seed': None,
    'train_seeds': None,
    # dataset config
    'train_dataset': None,
    'train_dataloader': None,
    'val_dataset': None,
    'val_dataloader': None,
    'test_dataset': None,
    'test_dataloader': None,
    'criterion': None,
    'metric': None,
    # model config
    'model': None,
    # optimizer config
    'optimizer': None,
    'scheduler': {
        'class': torch.optim.lr_scheduler.LambdaLR,
        'args': {
            'lr_lambda': {
                'class': schedulers.WarmupLambda,
                'args': {},
            },
        },
    },
}

from runners import SupervisedMultiTaskTrainer
config['runner'] = SupervisedMultiTaskTrainer

# dataset config
from configs.common.datasets.multi_task_learning.multi_mnist import config as dataset_config
config.update(dataset_config)

# model config
from configs.common.models.multi_task_learning.multi_mnist.multi_mnist_lenet5 import model_config_all_tasks as model_config
config['model'] = model_config

# optimizer config
from configs.common.optimizers.multi_task_learning.graddrop import optimizer_config
from configs.common.optimizers.standard import adam_optimizer_config
optimizer_config['args']['optimizer_config'] = adam_optimizer_config
optimizer_config['args']['per_layer'] = False
config['optimizer'] = optimizer_config

# seeds
config['init_seed'] = 75589482
config['train_seeds'] = [14371012, 56341670, 73612867, 90383288, 28709435, 39639390, 241172, 47222990, 48660785, 98256081, 61426011, 42492802, 71453949, 13827168, 99535767, 40704183, 28777416, 73903834, 54286794, 230925, 34514813, 23929773, 67933096, 67467708, 60449886, 97063909, 58598759, 43871363, 6682415, 95274944, 44550736, 39759893, 2548040, 24817986, 18692901, 67947967, 8444209, 77243217, 65644353, 2077138, 92675789, 51720111, 74737468, 44928526, 66528333, 7478935, 2234810, 90977552, 74353755, 40229907, 20712570, 34469023, 34172376, 55824378, 74491944, 10098274, 66011651, 22199656, 60854987, 71996590, 32991064, 58941496, 70873938, 95891869, 49021207, 6816937, 43855496, 86656808, 84518360, 38109637, 55901064, 25375493, 98562793, 25980341, 79492677, 93844685, 49381907, 86449914, 57769305, 1164130, 72434740, 64907759, 60393817, 37218538, 98077007, 21238668, 30405012, 55720884, 20244852, 66493573, 40732154, 22021471, 51194092, 55067708, 51379796, 75615761, 55117875, 85272857, 2666143, 3801378]

# work dir
config['work_dir'] = "./logs/benchmarks/multi_task_learning/multi_mnist/multi_mnist_lenet5/graddrop_run_2"
