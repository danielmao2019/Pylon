# This file is automatically generated by `./configs/benchmarks/multi_task_learning/gen_multi_task_learning.py`.
# Please do not attempt to modify manually.
import torch
import schedulers


config = {
    'runner': None,
    'work_dir': None,
    'epochs': 100,
    # seeds
    'init_seed': None,
    'train_seeds': None,
    'val_seeds': None,
    'test_seed': None,
    # dataset config
    'train_dataset': None,
    'train_dataloader': None,
    'val_dataset': None,
    'val_dataloader': None,
    'test_dataset': None,
    'test_dataloader': None,
    'criterion': None,
    'metric': None,
    # model config
    'model': None,
    # optimizer config
    'optimizer': None,
    'scheduler': {
        'class': torch.optim.lr_scheduler.LambdaLR,
        'args': {
            'lr_lambda': {
                'class': schedulers.lr_lambdas.WarmupLambda,
                'args': {},
            },
        },
    },
}

from runners import SupervisedMultiTaskTrainer
config['runner'] = SupervisedMultiTaskTrainer

# dataset config
from configs.common.datasets.multi_task_learning.multi_mnist import config as dataset_config
config.update(dataset_config)

# model config
from configs.common.models.multi_task_learning.multi_mnist.multi_mnist_lenet5 import model_config_all_tasks as model_config
config['model'] = model_config

# optimizer config
from configs.common.optimizers.multi_task_learning.mgda_ub import optimizer_config
from configs.common.optimizers.standard import adam_optimizer_config
optimizer_config['args']['optimizer_config'] = adam_optimizer_config
optimizer_config['args']['per_layer'] = False
config['optimizer'] = optimizer_config

# seeds
config['init_seed'] = 27060843
config['train_seeds'] = [22339293, 13010992, 46339220, 62361534, 3340757, 95489756, 76857081, 82347806, 91247051, 96471108, 88112208, 45802736, 90337698, 33918013, 64242289, 45022928, 45592351, 62015019, 46132703, 43423256, 3680110, 62926536, 75044398, 9255924, 47085463, 38160020, 5942983, 21696778, 90702347, 295047, 93010769, 79026306, 21700865, 99301349, 40570274, 79405130, 32061186, 79965682, 54370290, 89196740, 66863271, 50394024, 18258856, 34742086, 81655489, 59952676, 31860573, 14466882, 82718359, 28618390, 33194398, 81817175, 7330156, 81810719, 61364948, 45778388, 67904201, 48090324, 46076471, 50669618, 99794555, 28994298, 63299605, 18055786, 94241143, 69590374, 53307107, 16963645, 48395115, 79867772, 4085780, 54376340, 27406033, 38359962, 59464680, 57526572, 94637721, 40824944, 35911436, 71826067, 49011630, 47705526, 58240310, 84079895, 21430244, 74752164, 34050061, 90039408, 15412558, 96214333, 92580927, 78413448, 38954908, 65198819, 60137133, 73473047, 20090054, 79684523, 42076864, 35106401]
config['val_seeds'] = [54232383, 68906522, 88946612, 624854, 46109422, 38838377, 57853426, 66715429, 82671715, 40591230, 94517777, 41991232, 58859762, 21911428, 55018775, 92587868, 98329622, 59288893, 88979620, 8817932, 95725070, 3178040, 43732959, 55661871, 19817158, 76823344, 85234919, 9846737, 86186506, 37940555, 85645641, 78068330, 1162656, 97611535, 10061224, 19996906, 44855191, 5389110, 20474403, 40271469, 30270636, 93197664, 10163615, 97584604, 36156616, 53947725, 71242337, 85628353, 68402578, 89183403, 93741038, 24775555, 48644399, 22772139, 95686407, 46893876, 87640750, 89118620, 80128852, 22964979, 11753216, 16735412, 15644681, 41655837, 27388651, 41484949, 12487774, 93138305, 17026443, 71173996, 22678567, 84349681, 32988038, 16531830, 8814931, 72549367, 43951033, 26767147, 66876043, 19396431, 64843914, 49252410, 45104351, 20760028, 55603233, 6160599, 12373110, 53818271, 90690957, 47478221, 39735823, 21735890, 60654441, 90781749, 50553699, 753442, 48803780, 90911322, 57998297, 99942171]
config['test_seed'] = 55746677

# work dir
config['work_dir'] = "./logs/benchmarks/multi_task_learning/multi_mnist/multi_mnist_lenet5/mgda_ub_run_2"
