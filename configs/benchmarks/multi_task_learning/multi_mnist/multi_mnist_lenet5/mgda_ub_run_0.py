# This file is automatically generated by `./configs/benchmarks/multi_task_learning/gen_multi_task_learning.py`.
# Please do not attempt to modify manually.
import torch
import schedulers


config = {
    'runner': None,
    'work_dir': None,
    'epochs': 100,
    # seeds
    'init_seed': None,
    'train_seeds': None,
    # dataset config
    'train_dataset': None,
    'train_dataloader': None,
    'val_dataset': None,
    'val_dataloader': None,
    'test_dataset': None,
    'test_dataloader': None,
    'criterion': None,
    'metric': None,
    # model config
    'model': None,
    # optimizer config
    'optimizer': None,
    'scheduler': {
        'class': torch.optim.lr_scheduler.LambdaLR,
        'args': {
            'lr_lambda': {
                'class': schedulers.WarmupLambda,
                'args': {},
            },
        },
    },
}

from runners import SupervisedMultiTaskTrainer
config['runner'] = SupervisedMultiTaskTrainer

# dataset config
from configs.common.datasets.multi_task_learning.multi_mnist import config as dataset_config
config.update(dataset_config)

# model config
from configs.common.models.multi_task_learning.multi_mnist.multi_mnist_lenet5 import model_config_all_tasks as model_config
config['model'] = model_config

# optimizer config
from configs.common.optimizers.multi_task_learning.mgda_ub import optimizer_config
from configs.common.optimizers.standard import adam_optimizer_config
optimizer_config['args']['optimizer_config'] = adam_optimizer_config
optimizer_config['args']['per_layer'] = False
config['optimizer'] = optimizer_config

# seeds
config['init_seed'] = 41628137
config['train_seeds'] = [7451131, 32728620, 36585737, 44935680, 18082040, 59448316, 63684786, 53119654, 81628331, 42470954, 11901734, 89759800, 3840871, 9823487, 92391170, 73522970, 5907813, 5524080, 79229732, 45503994, 62823663, 720450, 75160443, 80158354, 89461334, 3776382, 71728750, 43770241, 43430266, 57929871, 30533972, 33575497, 54940733, 35038442, 79780213, 96393838, 26138946, 98462150, 77019032, 51622611, 57493322, 71576394, 10524150, 59556734, 30964694, 40989050, 10193139, 51647303, 16194424, 53276770, 99469719, 60857458, 27388139, 94078622, 53804354, 84998684, 13875032, 1343700, 47825237, 71204645, 90726388, 32313353, 9560228, 5103498, 28788214, 46321388, 19093432, 53944890, 46081682, 41512484, 84826723, 40770223, 98798040, 30341227, 77681783, 34914099, 12453761, 1239959, 29928647, 98887388, 82259511, 48497207, 53520451, 80964586, 75287573, 32773819, 19581874, 48852194, 17804522, 18743820, 48570537, 66378273, 63188816, 93871137, 10986772, 13066506, 12018227, 13723521, 35180299, 33517485]

# work dir
config['work_dir'] = "./logs/benchmarks/multi_task_learning/multi_mnist/multi_mnist_lenet5/mgda_ub_run_0"
