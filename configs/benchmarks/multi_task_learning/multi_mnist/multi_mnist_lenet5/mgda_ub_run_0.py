# This file is automatically generated by `./configs/benchmarks/multi_task_learning/gen_multi_task_learning.py`.
# Please do not attempt to modify manually.
import torch
import schedulers


config = {
    'runner': None,
    'work_dir': None,
    'epochs': 100,
    # seeds
    'init_seed': None,
    'train_seeds': None,
    'val_seeds': None,
    'test_seed': None,
    # dataset config
    'train_dataset': None,
    'train_dataloader': None,
    'val_dataset': None,
    'val_dataloader': None,
    'test_dataset': None,
    'test_dataloader': None,
    'criterion': None,
    'metric': None,
    # model config
    'model': None,
    # optimizer config
    'optimizer': None,
    'scheduler': {
        'class': torch.optim.lr_scheduler.LambdaLR,
        'args': {
            'lr_lambda': {
                'class': schedulers.lr_lambdas.WarmupLambda,
                'args': {},
            },
        },
    },
}

from runners import SupervisedMultiTaskTrainer
config['runner'] = SupervisedMultiTaskTrainer

# dataset config
from configs.common.datasets.multi_task_learning.multi_mnist import config as dataset_config
config.update(dataset_config)

# model config
from configs.common.models.multi_task_learning.multi_mnist.multi_mnist_lenet5 import model_config_all_tasks as model_config
config['model'] = model_config

# optimizer config
from configs.common.optimizers.multi_task_learning.mgda_ub import optimizer_config
from configs.common.optimizers.standard import adam_optimizer_config
optimizer_config['args']['optimizer_config'] = adam_optimizer_config
optimizer_config['args']['per_layer'] = False
config['optimizer'] = optimizer_config

# seeds
config['init_seed'] = 41628137
config['train_seeds'] = [7451131, 32728620, 36585737, 44935680, 18082040, 59448316, 63684786, 53119654, 81628331, 42470954, 11901734, 89759800, 3840871, 9823487, 92391170, 73522970, 5907813, 5524080, 79229732, 45503994, 62823663, 720450, 75160443, 80158354, 89461334, 3776382, 71728750, 43770241, 43430266, 57929871, 30533972, 33575497, 54940733, 35038442, 79780213, 96393838, 26138946, 98462150, 77019032, 51622611, 57493322, 71576394, 10524150, 59556734, 30964694, 40989050, 10193139, 51647303, 16194424, 53276770, 99469719, 60857458, 27388139, 94078622, 53804354, 84998684, 13875032, 1343700, 47825237, 71204645, 90726388, 32313353, 9560228, 5103498, 28788214, 46321388, 19093432, 53944890, 46081682, 41512484, 84826723, 40770223, 98798040, 30341227, 77681783, 34914099, 12453761, 1239959, 29928647, 98887388, 82259511, 48497207, 53520451, 80964586, 75287573, 32773819, 19581874, 48852194, 17804522, 18743820, 48570537, 66378273, 63188816, 93871137, 10986772, 13066506, 12018227, 13723521, 35180299, 33517485]
config['val_seeds'] = [55760501, 2187193, 69986719, 17100798, 41357197, 41686086, 51365000, 49758833, 52707103, 46519805, 25353899, 85335987, 11949224, 81747590, 25981050, 22131529, 43953117, 58744774, 4910698, 52150362, 21295900, 16302219, 36108375, 10270096, 19823951, 22892204, 93198820, 55072152, 87803813, 1497095, 21811501, 5416454, 54270023, 37454617, 74633831, 14632102, 94267988, 79078348, 87042413, 46644481, 60183428, 92671096, 8039234, 79084731, 43793983, 87871496, 92738645, 554310, 65431519, 56938456, 6220654, 14561842, 35717314, 29122987, 50397170, 39101454, 29459589, 8979273, 25211230, 92181095, 72894332, 1099972, 66809964, 42842653, 96242012, 14922673, 7553902, 65079965, 69605860, 20420066, 84411081, 95167960, 62293558, 82030581, 14823740, 4963290, 24635444, 22314318, 12416895, 38471521, 11711123, 55280720, 54372546, 15577434, 59995885, 93096058, 61096154, 48983720, 42760341, 47765607, 32321454, 66878703, 59238093, 49972711, 71578061, 20815818, 41336876, 45926411, 52431728, 39680889]
config['test_seed'] = 91205217

# work dir
config['work_dir'] = "./logs/benchmarks/multi_task_learning/multi_mnist/multi_mnist_lenet5/mgda_ub_run_0"
