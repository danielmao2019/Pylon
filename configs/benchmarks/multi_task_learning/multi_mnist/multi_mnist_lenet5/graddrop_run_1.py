# This file is automatically generated by `./configs/benchmarks/multi_task_learning/gen_multi_task_learning.py`.
# Please do not attempt to modify manually.
import torch
import schedulers


config = {
    'runner': None,
    'work_dir': None,
    'epochs': 100,
    # seeds
    'init_seed': None,
    'train_seeds': None,
    # dataset config
    'train_dataset': None,
    'train_dataloader': None,
    'val_dataset': None,
    'val_dataloader': None,
    'test_dataset': None,
    'test_dataloader': None,
    'criterion': None,
    'metric': None,
    # model config
    'model': None,
    # optimizer config
    'optimizer': None,
    'scheduler': {
        'class': torch.optim.lr_scheduler.LambdaLR,
        'args': {
            'lr_lambda': {
                'class': schedulers.WarmupLambda,
                'args': {},
            },
        },
    },
}

from runners import SupervisedMultiTaskTrainer
config['runner'] = SupervisedMultiTaskTrainer

# dataset config
from configs.common.datasets.multi_task_learning.multi_mnist import config as dataset_config
config.update(dataset_config)

# model config
from configs.common.models.multi_task_learning.multi_mnist.multi_mnist_lenet5 import model_config_all_tasks as model_config
config['model'] = model_config

# optimizer config
from configs.common.optimizers.multi_task_learning.graddrop import optimizer_config
from configs.common.optimizers.standard import adam_optimizer_config
optimizer_config['args']['optimizer_config'] = adam_optimizer_config
optimizer_config['args']['per_layer'] = False
config['optimizer'] = optimizer_config

# seeds
config['init_seed'] = 11070694
config['train_seeds'] = [38774181, 41511254, 25398200, 41970690, 54476566, 54955599, 65758216, 32992115, 41174564, 84329895, 46132715, 69106466, 64257109, 61303355, 18450623, 26385114, 93355865, 78251462, 44357202, 47810654, 98503462, 68494901, 7072003, 7677378, 11793337, 89053009, 70573017, 10940056, 8243645, 15726367, 40025948, 83091577, 24915097, 47728589, 99061061, 70203584, 30377720, 68945194, 4655687, 99526875, 17881793, 8098041, 23651826, 82343042, 52230330, 665544, 26338552, 73339981, 41336481, 31259865, 31251207, 79243053, 26114525, 86345805, 23854437, 42540173, 18971101, 56048560, 3402861, 1984845, 54344051, 52992, 39749242, 1273967, 17182571, 20601421, 47495652, 9240442, 42552492, 45623652, 43574154, 27975336, 31115772, 79948386, 19215870, 34378380, 94935867, 41987814, 6312093, 18303293, 34571297, 65710336, 88494249, 97435072, 41373230, 91318158, 5612120, 55444565, 4297419, 70490805, 6593576, 30343741, 6141616, 42704822, 44385925, 70855464, 74015688, 52593989, 75207109, 73319640]

# work dir
config['work_dir'] = "./logs/benchmarks/multi_task_learning/multi_mnist/multi_mnist_lenet5/graddrop_run_1"
