# This file is automatically generated by `./configs/benchmarks/multi_task_learning/gen_multi_task_learning.py`.
# Please do not attempt to modify manually.
import torch
import schedulers


config = {
    'runner': None,
    'work_dir': None,
    'epochs': 100,
    # seeds
    'init_seed': None,
    'train_seeds': None,
    'val_seeds': None,
    'test_seed': None,
    # dataset config
    'train_dataset': None,
    'train_dataloader': None,
    'val_dataset': None,
    'val_dataloader': None,
    'test_dataset': None,
    'test_dataloader': None,
    'criterion': None,
    'metric': None,
    # model config
    'model': None,
    # optimizer config
    'optimizer': None,
    'scheduler': {
        'class': torch.optim.lr_scheduler.LambdaLR,
        'args': {
            'lr_lambda': {
                'class': schedulers.lr_lambdas.WarmupLambda,
                'args': {},
            },
        },
    },
}

from runners import SupervisedMultiTaskTrainer
config['runner'] = SupervisedMultiTaskTrainer

# dataset config
from configs.common.datasets.multi_task_learning.multi_mnist import config as dataset_config
config.update(dataset_config)

# model config
from configs.common.models.multi_task_learning.multi_mnist.multi_mnist_lenet5 import model_config_all_tasks as model_config
config['model'] = model_config

# optimizer config
from configs.common.optimizers.multi_task_learning.pcgrad import optimizer_config
from configs.common.optimizers.standard import adam_optimizer_config
optimizer_config['args']['optimizer_config'] = adam_optimizer_config
optimizer_config['args']['per_layer'] = False
config['optimizer'] = optimizer_config

# seeds
config['init_seed'] = 4143874
config['train_seeds'] = [98226719, 60768145, 82374572, 88865330, 98460956, 66336625, 39739004, 9404207, 95326839, 14091518, 68303406, 12443757, 47634675, 63663003, 30193975, 10630959, 1352499, 60159662, 20328820, 65984339, 37721288, 91765836, 14361780, 14864767, 2703643, 64499285, 20224930, 2035369, 38772353, 50852916, 95536008, 13077356, 15962896, 93974749, 69506604, 52248945, 66593340, 67537613, 95034908, 62116338, 62313248, 1040836, 18459296, 7878567, 55671622, 10294323, 48349589, 88426816, 48970611, 632009, 56668127, 25229725, 15906356, 64422541, 7153112, 8499323, 69535441, 46215246, 26248342, 54260847, 1041275, 64203588, 93350224, 94182978, 88801316, 74196383, 55227834, 9341258, 29701310, 34130790, 76622187, 78915577, 30756826, 18211046, 63365669, 229115, 53554552, 39072066, 19147786, 95032202, 50658403, 40392524, 73882971, 34867212, 32737131, 58191679, 99780187, 72537292, 17544199, 19997970, 52245669, 15830775, 97074411, 86495671, 65671721, 15705305, 73731286, 72749464, 39932111, 95160086]
config['val_seeds'] = [80258448, 55196894, 6125685, 93944713, 48113750, 17690783, 36720308, 55150236, 4312753, 26576728, 94242625, 38368803, 5403641, 66112643, 8743994, 17196663, 58086973, 95863009, 19897169, 94469317, 96455049, 24229512, 67482488, 71287105, 38433936, 68247943, 71461392, 90936503, 74550253, 1893635, 67085808, 86419825, 92649794, 95699416, 50757184, 66425515, 89614071, 31100769, 38351507, 18511088, 77269992, 36861766, 68009, 8836152, 41972339, 49314129, 88151969, 1795050, 3157209, 98212965, 28235648, 4574354, 46139987, 93019939, 15488824, 70889077, 44626390, 79750829, 29762181, 46330841, 62907373, 60699426, 93464438, 72784368, 40738381, 26981512, 20218394, 85554784, 86343395, 68237418, 94076200, 94524121, 9860232, 53178996, 98902044, 5565085, 39523858, 46237783, 29182759, 19983199, 2182987, 85666550, 69267404, 92107546, 462995, 21927928, 59542479, 64592797, 21352571, 39739124, 29342370, 67362759, 76443886, 56078920, 9463961, 46223407, 6937628, 10467739, 19117064, 49248248]
config['test_seed'] = 72918411

# work dir
config['work_dir'] = "./logs/benchmarks/multi_task_learning/multi_mnist/multi_mnist_lenet5/pcgrad_run_0"
