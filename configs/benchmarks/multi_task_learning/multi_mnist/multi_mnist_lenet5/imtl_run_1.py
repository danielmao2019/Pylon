# This file is automatically generated by `./configs/benchmarks/multi_task_learning/gen_multi_task_learning.py`.
# Please do not attempt to modify manually.
import torch
import schedulers


config = {
    'runner': None,
    'work_dir': None,
    'epochs': 100,
    # seeds
    'init_seed': None,
    'train_seeds': None,
    'val_seeds': None,
    'test_seed': None,
    # dataset config
    'train_dataset': None,
    'train_dataloader': None,
    'val_dataset': None,
    'val_dataloader': None,
    'test_dataset': None,
    'test_dataloader': None,
    'criterion': None,
    'metric': None,
    # model config
    'model': None,
    # optimizer config
    'optimizer': None,
    'scheduler': {
        'class': torch.optim.lr_scheduler.LambdaLR,
        'args': {
            'lr_lambda': {
                'class': schedulers.lr_lambdas.WarmupLambda,
                'args': {},
            },
        },
    },
}

from runners import SupervisedMultiTaskTrainer
config['runner'] = SupervisedMultiTaskTrainer

# dataset config
from configs.common.datasets.multi_task_learning.multi_mnist import config as dataset_config
config.update(dataset_config)

# model config
from configs.common.models.multi_task_learning.multi_mnist.multi_mnist_lenet5 import model_config_all_tasks as model_config
config['model'] = model_config

# optimizer config
from configs.common.optimizers.multi_task_learning.imtl import optimizer_config
from configs.common.optimizers.standard import adam_optimizer_config
optimizer_config['args']['optimizer_config'] = adam_optimizer_config
optimizer_config['args']['per_layer'] = False
config['optimizer'] = optimizer_config

# seeds
config['init_seed'] = 28231950
config['train_seeds'] = [44057139, 3717058, 12803111, 6319014, 13490525, 46948030, 97945114, 21092413, 19546680, 20265305, 56486685, 78915593, 41867367, 89506950, 21038998, 15616730, 59990631, 82237102, 78026450, 50266839, 78055176, 79339667, 82077516, 68944551, 91652879, 63634961, 55175319, 55858074, 29119468, 80262792, 99526689, 71784829, 56121011, 91444958, 28075352, 32218580, 1946532, 17182105, 78883191, 57009466, 11008383, 81308087, 98925112, 27524660, 76989328, 69984544, 44183373, 6596426, 54789310, 31410346, 22173995, 96064911, 61021878, 79095960, 82469252, 74257027, 57884613, 53936717, 6982554, 1734550, 47295574, 83786192, 43182963, 32251691, 68811623, 88007818, 68064569, 19047854, 14638484, 57806123, 32454110, 12803790, 8413478, 88444533, 3465207, 25331592, 90070830, 62543766, 15311692, 55505212, 14423632, 40467418, 26692497, 28420432, 77280250, 59086343, 94591772, 52118375, 79853683, 42913806, 65146815, 93372800, 13246610, 5959181, 21765445, 67967081, 91233207, 55338222, 74408450, 91680967]
config['val_seeds'] = [62076809, 34973149, 39294650, 56615683, 96322243, 76679330, 24070848, 80228192, 52206716, 52020595, 7409093, 10084347, 46720080, 55003099, 69146507, 93880003, 76417127, 44906104, 25233126, 41993652, 59743131, 23154562, 14123734, 33992762, 48208760, 28548169, 72600214, 42872093, 82240939, 82477222, 4260793, 89423426, 87960561, 88597088, 820386, 89911966, 12992339, 23223575, 21298861, 80440858, 29727888, 61216196, 98375080, 29428667, 5050719, 33720309, 25311109, 7260272, 77021889, 79350193, 83188234, 18588746, 19291497, 48411583, 26724364, 49690356, 56426535, 70380433, 99420039, 15496319, 51271255, 59128761, 57213282, 72021732, 46432338, 55091115, 76736199, 56487535, 74854632, 10213622, 37877264, 8857540, 5213584, 76286130, 38371667, 9571567, 58899354, 2864570, 40906068, 18889225, 22944538, 49107518, 15317611, 20620215, 21687376, 97201335, 33632526, 86793413, 62926452, 95914950, 45946254, 49654284, 66309002, 69422424, 81801632, 8175251, 65641762, 15085875, 75793153, 7521595]
config['test_seed'] = 10484702

# work dir
config['work_dir'] = "./logs/benchmarks/multi_task_learning/multi_mnist/multi_mnist_lenet5/imtl_run_1"
