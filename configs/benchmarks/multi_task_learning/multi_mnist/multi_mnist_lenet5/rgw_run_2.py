# This file is automatically generated by `./configs/benchmarks/multi_task_learning/gen_multi_task_learning.py`.
# Please do not attempt to modify manually.
import torch
import schedulers


config = {
    'runner': None,
    'work_dir': None,
    'epochs': 100,
    # seeds
    'init_seed': None,
    'train_seeds': None,
    'val_seeds': None,
    'test_seed': None,
    # dataset config
    'train_dataset': None,
    'train_dataloader': None,
    'val_dataset': None,
    'val_dataloader': None,
    'test_dataset': None,
    'test_dataloader': None,
    'criterion': None,
    'metric': None,
    # model config
    'model': None,
    # optimizer config
    'optimizer': None,
    'scheduler': {
        'class': torch.optim.lr_scheduler.LambdaLR,
        'args': {
            'lr_lambda': {
                'class': schedulers.lr_lambdas.WarmupLambda,
                'args': {},
            },
        },
    },
}

from runners import SupervisedMultiTaskTrainer
config['runner'] = SupervisedMultiTaskTrainer

# dataset config
from configs.common.datasets.multi_task_learning.multi_mnist import config as dataset_config
config.update(dataset_config)

# model config
from configs.common.models.multi_task_learning.multi_mnist.multi_mnist_lenet5 import model_config_all_tasks as model_config
config['model'] = model_config

# optimizer config
from configs.common.optimizers.multi_task_learning.rgw import optimizer_config
from configs.common.optimizers.standard import adam_optimizer_config
optimizer_config['args']['optimizer_config'] = adam_optimizer_config
optimizer_config['args']['per_layer'] = False
config['optimizer'] = optimizer_config

# seeds
config['init_seed'] = 84881703
config['train_seeds'] = [43095981, 38446998, 43352885, 2445534, 44599010, 94316227, 36239406, 25493216, 37899600, 69608363, 20464431, 33602546, 942765, 69966886, 57330438, 66909289, 48960664, 77667424, 6243, 49446226, 80347396, 51465931, 73016993, 69292215, 36423847, 52265967, 16185652, 41023331, 15430355, 59436260, 6295005, 77166043, 13716250, 10579706, 95532277, 75220381, 5000705, 33200934, 10140262, 16030004, 2958004, 25170950, 38754463, 5619166, 28178101, 6583814, 94462477, 46627786, 66888377, 7913120, 3120984, 84340983, 52748578, 20985401, 17733871, 12110011, 57412382, 56277879, 16913881, 94626545, 50149124, 60129719, 79580718, 45382038, 88462532, 49071364, 30767571, 29450794, 58741017, 67291906, 74931727, 70683819, 20459689, 18841570, 54525867, 76775750, 39456148, 63575126, 37217175, 34075803, 82025730, 21755874, 54885380, 39526341, 32093715, 39083573, 95358351, 88903483, 78350927, 98820830, 66774912, 61057267, 44274658, 46041262, 65476630, 6527795, 38546098, 73279026, 73748059, 67418513]
config['val_seeds'] = [9446906, 68589552, 89284736, 80886059, 85302674, 51107046, 11684917, 27875685, 55805593, 75439888, 93481272, 67584871, 9132544, 27513245, 18875483, 38561061, 26040960, 44576690, 1688558, 10577105, 7799146, 93266342, 63719330, 66203203, 69503955, 59528986, 32595890, 29552420, 39327151, 82185307, 34241710, 92342472, 28177192, 52667243, 91106936, 77048466, 64528403, 89942634, 52868680, 87685725, 35938454, 52100376, 35028997, 74052894, 52932507, 90229810, 6056611, 62106792, 83308121, 37059858, 98021878, 64388027, 12169542, 64247221, 24919731, 16856169, 20092955, 69530348, 68416706, 46001910, 27027904, 53996046, 37196614, 94317899, 63537952, 67141545, 17073293, 66783546, 15344776, 99451341, 93251276, 9713121, 13786865, 63653324, 1598959, 98037799, 83963052, 33928467, 72767812, 50917249, 39494898, 52091219, 34695776, 24934646, 71874984, 5474353, 8169943, 56540188, 57442396, 79240017, 10074792, 90455389, 35370691, 29589220, 15534020, 75790137, 38489169, 46632548, 39346164, 76127447]
config['test_seed'] = 36889543

# work dir
config['work_dir'] = "./logs/benchmarks/multi_task_learning/multi_mnist/multi_mnist_lenet5/rgw_run_2"
