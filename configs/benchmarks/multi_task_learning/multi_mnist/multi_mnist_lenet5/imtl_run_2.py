# This file is automatically generated by `./configs/benchmarks/multi_task_learning/gen_multi_task_learning.py`.
# Please do not attempt to modify manually.
import torch
import schedulers


config = {
    'runner': None,
    'work_dir': None,
    'epochs': 100,
    # seeds
    'init_seed': None,
    'train_seeds': None,
    'val_seeds': None,
    'test_seed': None,
    # dataset config
    'train_dataset': None,
    'train_dataloader': None,
    'val_dataset': None,
    'val_dataloader': None,
    'test_dataset': None,
    'test_dataloader': None,
    'criterion': None,
    'metric': None,
    # model config
    'model': None,
    # optimizer config
    'optimizer': None,
    'scheduler': {
        'class': torch.optim.lr_scheduler.LambdaLR,
        'args': {
            'lr_lambda': {
                'class': schedulers.lr_lambdas.WarmupLambda,
                'args': {},
            },
        },
    },
}

from runners import SupervisedMultiTaskTrainer
config['runner'] = SupervisedMultiTaskTrainer

# dataset config
from configs.common.datasets.multi_task_learning.multi_mnist import config as dataset_config
config.update(dataset_config)

# model config
from configs.common.models.multi_task_learning.multi_mnist.multi_mnist_lenet5 import model_config_all_tasks as model_config
config['model'] = model_config

# optimizer config
from configs.common.optimizers.multi_task_learning.imtl import optimizer_config
from configs.common.optimizers.standard import adam_optimizer_config
optimizer_config['args']['optimizer_config'] = adam_optimizer_config
optimizer_config['args']['per_layer'] = False
config['optimizer'] = optimizer_config

# seeds
config['init_seed'] = 97088737
config['train_seeds'] = [45863849, 91679842, 50426401, 40735984, 8501961, 40758144, 83742993, 16445251, 99854108, 75838465, 73018577, 81024369, 9990343, 87819847, 63646632, 75080581, 38401027, 6533076, 43369398, 52212083, 20418486, 84700663, 31873263, 54825039, 62506965, 17426506, 45114346, 42621275, 87768143, 57031912, 66498816, 24049180, 12953408, 64557538, 50264770, 69938611, 28279721, 79971245, 2135737, 57206203, 15540932, 86700256, 86045982, 57227395, 57660600, 63451022, 52739007, 71874796, 22280087, 33030453, 6006538, 14445597, 93677369, 62251763, 21138666, 3268989, 5027655, 14331781, 66909489, 46858054, 55003531, 68833530, 67550895, 99935139, 24200540, 79288207, 18833690, 39252013, 16662731, 25635778, 38617362, 56983529, 78798714, 88659847, 74089893, 96200620, 68647963, 16415762, 9269767, 57541132, 2761447, 53675800, 79945558, 30378993, 36670387, 75521322, 67905251, 27616462, 84154310, 84805746, 81342549, 98962779, 16258383, 30884397, 77465297, 11724909, 99852381, 28651715, 13796449, 53561902]
config['val_seeds'] = [7147298, 29340864, 49170262, 66939694, 29059318, 59737185, 36412759, 86682794, 50409182, 67863746, 73062341, 1201596, 95734817, 29403593, 55991901, 91643354, 77328487, 89066008, 73226290, 23392759, 57686774, 81621617, 21542290, 20032981, 96437884, 13396036, 92661626, 56739825, 44520589, 22106174, 56035394, 26397067, 31124915, 58543871, 66471999, 3308853, 66550662, 60983385, 92612306, 83937687, 65602105, 24494245, 49790226, 18357895, 16794766, 63591035, 41037319, 27595790, 28299072, 28035328, 88201210, 48457620, 32239732, 86465061, 83095586, 14576687, 56245144, 83238089, 61465103, 70024172, 38108125, 44586405, 11278200, 23495750, 77053243, 9032184, 78867438, 60167479, 15379488, 79850828, 10391135, 78365708, 98550532, 58168281, 49807937, 40553200, 71015285, 98600510, 86911724, 4598082, 47556760, 38510242, 75853298, 5990108, 88645130, 3418847, 8755125, 88183625, 74105774, 56679681, 33049930, 45641022, 42576684, 93590234, 94663899, 86098492, 87560060, 53690983, 35230655, 88243719]
config['test_seed'] = 88076891

# work dir
config['work_dir'] = "./logs/benchmarks/multi_task_learning/multi_mnist/multi_mnist_lenet5/imtl_run_2"
