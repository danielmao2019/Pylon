# This file is automatically generated by `./configs/benchmarks/multi_task_learning/gen_multi_task_learning.py`.
# Please do not attempt to modify manually.
import torch
import schedulers


config = {
    'runner': None,
    'work_dir': None,
    'epochs': 100,
    # seeds
    'init_seed': None,
    'train_seeds': None,
    'val_seeds': None,
    'test_seed': None,
    # dataset config
    'train_dataset': None,
    'train_dataloader': None,
    'val_dataset': None,
    'val_dataloader': None,
    'test_dataset': None,
    'test_dataloader': None,
    'criterion': None,
    'metric': None,
    # model config
    'model': None,
    # optimizer config
    'optimizer': None,
    'scheduler': {
        'class': torch.optim.lr_scheduler.LambdaLR,
        'args': {
            'lr_lambda': {
                'class': schedulers.lr_lambdas.WarmupLambda,
                'args': {},
            },
        },
    },
}

from runners import SupervisedMultiTaskTrainer
config['runner'] = SupervisedMultiTaskTrainer

# dataset config
from configs.common.datasets.multi_task_learning.multi_mnist import config as dataset_config
config.update(dataset_config)

# model config
from configs.common.models.multi_task_learning.multi_mnist.multi_mnist_lenet5 import model_config_all_tasks as model_config
config['model'] = model_config

# optimizer config
from configs.common.optimizers.multi_task_learning.cagrad import optimizer_config
from configs.common.optimizers.standard import adam_optimizer_config
optimizer_config['args']['optimizer_config'] = adam_optimizer_config
optimizer_config['args']['per_layer'] = False
config['optimizer'] = optimizer_config

# seeds
config['init_seed'] = 57471062
config['train_seeds'] = [55096050, 1761482, 16603418, 82714456, 96355913, 32156136, 87570907, 90918755, 81109193, 12635991, 71196023, 82640015, 54667649, 49182225, 39906362, 8400597, 15345034, 18717867, 10436426, 17029414, 1726025, 50632608, 81192324, 77832562, 87482428, 77691549, 50106041, 23664371, 86648089, 10555365, 82866598, 59333474, 61357142, 3900027, 2136207, 11381494, 64208917, 26340093, 56858222, 82840953, 98602402, 32872166, 87916750, 81168305, 91681423, 40428664, 62900758, 82064315, 80119044, 28630605, 27232406, 12726732, 69824999, 80365970, 37135793, 12161238, 69969008, 52369106, 90163946, 56605360, 53469092, 76247133, 45077093, 15433887, 4616813, 87605439, 99671799, 92872572, 177006, 84515778, 77505997, 51230800, 92302767, 17491021, 30153818, 44312081, 6109371, 11807577, 52244628, 58325352, 25477614, 69451084, 23718614, 30097553, 39779294, 23699245, 6513605, 10764858, 21023464, 40053490, 23828351, 43788927, 13548388, 78422911, 23678872, 53915872, 61273713, 27425997, 15312603, 11349768]
config['val_seeds'] = [9991078, 45544593, 45239830, 31975750, 84951698, 51953541, 3733134, 27602207, 35411000, 67512663, 85591685, 84892491, 26729075, 41188489, 60039964, 9567168, 48723477, 54950332, 40408559, 23536821, 33592612, 71010207, 13287701, 65797743, 52614228, 47844551, 83242893, 40858145, 38712167, 63081296, 85564686, 67973137, 89376896, 62850366, 75262884, 13004549, 80284383, 35631475, 88163545, 35367500, 57693182, 34407169, 47038314, 64710185, 41604241, 97714038, 51515264, 84702181, 27233885, 36569662, 62399551, 21142847, 95514059, 4375678, 65794291, 43245814, 16210234, 66856977, 94856804, 73046268, 75451158, 13769772, 50271735, 19857238, 15447793, 16971201, 99993313, 55828970, 12008010, 26343700, 33538173, 83384006, 5361254, 73448797, 38227062, 72679316, 92638889, 43429216, 51037781, 16577392, 48358771, 66113759, 68919702, 38774338, 15990295, 92154591, 92957047, 16941283, 16607515, 60793297, 46501636, 51667905, 64843587, 17080494, 15752325, 59877043, 91653318, 67532, 87101210, 37917090]
config['test_seed'] = 95937061

# work dir
config['work_dir'] = "./logs/benchmarks/multi_task_learning/multi_mnist/multi_mnist_lenet5/cagrad_run_2"
