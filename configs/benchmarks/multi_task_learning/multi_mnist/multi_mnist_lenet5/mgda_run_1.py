# This file is automatically generated by `./configs/benchmarks/multi_task_learning/gen_multi_task_learning.py`.
# Please do not attempt to modify manually.
import torch
import schedulers


config = {
    'runner': None,
    'work_dir': None,
    'epochs': 100,
    # seeds
    'init_seed': None,
    'train_seeds': None,
    'val_seeds': None,
    'test_seed': None,
    # dataset config
    'train_dataset': None,
    'train_dataloader': None,
    'val_dataset': None,
    'val_dataloader': None,
    'test_dataset': None,
    'test_dataloader': None,
    'criterion': None,
    'metric': None,
    # model config
    'model': None,
    # optimizer config
    'optimizer': None,
    'scheduler': {
        'class': torch.optim.lr_scheduler.LambdaLR,
        'args': {
            'lr_lambda': {
                'class': schedulers.lr_lambdas.WarmupLambda,
                'args': {},
            },
        },
    },
}

from runners import SupervisedMultiTaskTrainer
config['runner'] = SupervisedMultiTaskTrainer

# dataset config
from configs.common.datasets.multi_task_learning.multi_mnist import config as dataset_config
config.update(dataset_config)

# model config
from configs.common.models.multi_task_learning.multi_mnist.multi_mnist_lenet5 import model_config_all_tasks as model_config
config['model'] = model_config

# optimizer config
from configs.common.optimizers.multi_task_learning.mgda import optimizer_config
from configs.common.optimizers.standard import adam_optimizer_config
optimizer_config['args']['optimizer_config'] = adam_optimizer_config
optimizer_config['args']['per_layer'] = False
config['optimizer'] = optimizer_config

# seeds
config['init_seed'] = 44437213
config['train_seeds'] = [26913392, 85020313, 7201215, 26307754, 3168100, 18864469, 29648033, 60868789, 95221894, 33993780, 66675685, 84250061, 90131573, 76675393, 8163609, 32952961, 25722589, 60926030, 55206657, 71336189, 70073196, 79650294, 91679927, 63909931, 15814426, 5174212, 36544052, 81628231, 91059214, 39553656, 85427595, 25664010, 29270022, 62610873, 84302364, 32324742, 80625190, 97025146, 1616880, 99655360, 71203194, 35498615, 55917148, 46605327, 18297035, 2892477, 34983607, 74180703, 20523215, 17278998, 55589897, 31467995, 14356697, 10786150, 97334159, 41701366, 81811833, 45997341, 697881, 47925371, 36583599, 71472111, 5917301, 75353975, 44434225, 95211082, 58354403, 73174030, 24334679, 69311178, 80879987, 81287126, 37916238, 60794172, 15533443, 84546109, 18703833, 42464800, 53593466, 41270285, 35063646, 2334898, 82596244, 79088014, 81511543, 96129157, 3932789, 36656378, 98444343, 60472755, 90249520, 82198912, 87950269, 85545916, 80715930, 64371205, 7657722, 8368651, 70344055, 36447807]
config['val_seeds'] = [13093000, 42487790, 29404793, 27325413, 50765252, 15792604, 71836135, 31883342, 20315062, 46564334, 38116726, 99373166, 974581, 46852330, 3915818, 19838918, 54731227, 76800769, 88138537, 17198305, 62764257, 97471262, 77158304, 80052091, 52728807, 89576189, 81051857, 80530459, 81846981, 25914649, 4773640, 89414824, 34276176, 56123917, 87990317, 14766745, 85446092, 8895514, 15906969, 94581790, 94541064, 18463335, 49283170, 63285046, 7199608, 35061949, 86269220, 48492877, 75823276, 34917750, 28576887, 13356232, 17730623, 37862143, 52202511, 44678086, 46028949, 18959580, 66104623, 76264795, 121673, 36132280, 52479024, 37133216, 31791809, 1096280, 18871228, 90476453, 40752158, 61719281, 86101353, 81975653, 15599221, 1644243, 354708, 64228462, 26062753, 3716862, 42925312, 46919351, 94621916, 33545025, 1997312, 82889891, 28756469, 72547898, 2013872, 51193932, 1934353, 56373753, 1977971, 21083355, 82484270, 66501360, 47334007, 2233917, 51677404, 86830504, 71414805, 96966341]
config['test_seed'] = 1395273

# work dir
config['work_dir'] = "./logs/benchmarks/multi_task_learning/multi_mnist/multi_mnist_lenet5/mgda_run_1"
