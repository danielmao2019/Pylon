# This file is automatically generated by `./configs/benchmarks/multi_task_learning/gen_multi_task_learning.py`.
# Please do not attempt to modify manually.
import torch
import schedulers


config = {
    'runner': None,
    'work_dir': None,
    'epochs': 100,
    # seeds
    'init_seed': None,
    'train_seeds': None,
    'val_seeds': None,
    'test_seed': None,
    # dataset config
    'train_dataset': None,
    'train_dataloader': None,
    'val_dataset': None,
    'val_dataloader': None,
    'test_dataset': None,
    'test_dataloader': None,
    'criterion': None,
    'metric': None,
    # model config
    'model': None,
    # optimizer config
    'optimizer': None,
    'scheduler': {
        'class': torch.optim.lr_scheduler.LambdaLR,
        'args': {
            'lr_lambda': {
                'class': schedulers.lr_lambdas.WarmupLambda,
                'args': {},
            },
        },
    },
}

from runners import SupervisedMultiTaskTrainer
config['runner'] = SupervisedMultiTaskTrainer

# dataset config
from configs.common.datasets.multi_task_learning.multi_mnist import config as dataset_config
config.update(dataset_config)

# model config
from configs.common.models.multi_task_learning.multi_mnist.multi_mnist_lenet5 import model_config_all_tasks as model_config
config['model'] = model_config

# optimizer config
from configs.common.optimizers.multi_task_learning.mgda import optimizer_config
from configs.common.optimizers.standard import adam_optimizer_config
optimizer_config['args']['optimizer_config'] = adam_optimizer_config
optimizer_config['args']['per_layer'] = False
config['optimizer'] = optimizer_config

# seeds
config['init_seed'] = 79937839
config['train_seeds'] = [20962248, 22813102, 65821163, 81357783, 8849482, 4075361, 36771446, 31917321, 96932214, 16279816, 69800155, 60139620, 20754730, 42577379, 58947776, 61442273, 95150609, 81230114, 24203618, 150179, 84263802, 43129919, 86839196, 18845333, 5511867, 8514768, 15902679, 29256815, 46976288, 61793347, 11968575, 42584798, 68021712, 41811025, 24473412, 34023691, 88935564, 81694720, 60209872, 10909240, 55927048, 58909169, 68612934, 61299787, 49025014, 20594093, 46995388, 77969673, 93495694, 44179369, 51501100, 71938566, 60231903, 23510414, 1389544, 61865827, 80750161, 41832871, 48486980, 19472594, 36980134, 49575565, 3131208, 73384428, 55909628, 13810098, 3695425, 52810501, 77498853, 8489698, 38566136, 63839418, 32337605, 19886676, 41351422, 92853234, 45834658, 80462585, 22813655, 14617429, 68202648, 46913840, 7200694, 44171980, 96092757, 20428230, 95501536, 52504319, 41111555, 3371543, 22478992, 87247601, 50814009, 13596324, 69050082, 11754473, 33928767, 73732894, 92234688, 32392687]
config['val_seeds'] = [70067173, 84890000, 20867620, 87643276, 57574874, 54081741, 85653877, 21720278, 5752036, 51940184, 47039584, 25084908, 62994895, 43730711, 7975109, 95435144, 37157793, 59969418, 59303141, 56708038, 97017064, 34127126, 87608442, 81646544, 12771039, 39657794, 73809746, 36511592, 73421362, 47184724, 62074530, 34333661, 44282021, 50096141, 35379493, 3783652, 70394906, 48777110, 94745058, 32082160, 55021848, 66545829, 5655544, 16283152, 33565731, 59272301, 94766498, 90913442, 86887091, 28913189, 48634562, 67530075, 80878742, 97988055, 68593340, 99166495, 49832537, 29686332, 19432904, 54289295, 97216317, 26215319, 12570842, 63809461, 8265574, 78210354, 44388584, 46266105, 13254709, 76755145, 94020427, 98933165, 35122029, 27755930, 72294483, 1991433, 34435909, 84229675, 41317660, 28999680, 66603243, 18831381, 36163858, 18654081, 29099714, 52046900, 11496380, 80208126, 70323789, 12721510, 20864523, 57508280, 38003846, 27057229, 74362142, 13619056, 43050919, 99238780, 73929991, 44229099]
config['test_seed'] = 42599872

# work dir
config['work_dir'] = "./logs/benchmarks/multi_task_learning/multi_mnist/multi_mnist_lenet5/mgda_run_0"
