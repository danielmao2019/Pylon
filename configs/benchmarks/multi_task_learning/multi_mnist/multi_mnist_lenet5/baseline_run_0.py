# This file is automatically generated by `./configs/benchmarks/multi_task_learning/gen_multi_task_learning.py`.
# Please do not attempt to modify manually.
import torch
import schedulers


config = {
    'runner': None,
    'work_dir': None,
    'epochs': 100,
    # seeds
    'init_seed': None,
    'train_seeds': None,
    # dataset config
    'train_dataset': None,
    'train_dataloader': None,
    'val_dataset': None,
    'val_dataloader': None,
    'test_dataset': None,
    'test_dataloader': None,
    'criterion': None,
    'metric': None,
    # model config
    'model': None,
    # optimizer config
    'optimizer': None,
    'scheduler': {
        'class': torch.optim.lr_scheduler.LambdaLR,
        'args': {
            'lr_lambda': {
                'class': schedulers.WarmupLambda,
                'args': {},
            },
        },
    },
}

from runners import SupervisedMultiTaskTrainer
config['runner'] = SupervisedMultiTaskTrainer

# dataset config
from configs.common.datasets.multi_task_learning.multi_mnist import config as dataset_config
config.update(dataset_config)

# model config
from configs.common.models.multi_task_learning.multi_mnist.multi_mnist_lenet5 import model_config_all_tasks as model_config
config['model'] = model_config

# optimizer config
from configs.common.optimizers.multi_task_learning.baseline import optimizer_config
from configs.common.optimizers.standard import adam_optimizer_config
optimizer_config['args']['optimizer_config'] = adam_optimizer_config
optimizer_config['args']['per_layer'] = False
config['optimizer'] = optimizer_config

# seeds
config['init_seed'] = 98318451
config['train_seeds'] = [26817658, 89159145, 62957891, 3181980, 23507728, 16992848, 28009725, 64593849, 79767188, 35205289, 31065930, 78697474, 63745403, 33624672, 50081760, 35441589, 57470424, 87820753, 55709585, 49065736, 93414474, 66555285, 2751034, 80912564, 62664804, 87295824, 53022721, 2847421, 2885484, 18433237, 31055395, 75725509, 10516892, 71972026, 84689438, 25553047, 43995481, 6303589, 5246656, 27055872, 42574924, 93337827, 29400927, 86664746, 47151505, 78365771, 9537348, 85938863, 74368684, 56842761, 76590279, 41056576, 64861338, 87398827, 51173829, 94896551, 4730715, 96630765, 18533120, 12602305, 98714306, 47212523, 82430126, 71003856, 93564116, 43423169, 24272113, 20178498, 40965750, 25939003, 24926053, 33347816, 12625097, 22272974, 246359, 48021849, 7110637, 91060365, 64596782, 65730923, 92415640, 51300585, 18024499, 56591743, 14964469, 87613072, 18830570, 79435237, 29103956, 74391171, 77878808, 76505177, 79241284, 68025135, 24815020, 18405789, 14087593, 42338009, 93328217, 23781198]

# work dir
config['work_dir'] = "./logs/benchmarks/multi_task_learning/multi_mnist/multi_mnist_lenet5/baseline_run_0"
