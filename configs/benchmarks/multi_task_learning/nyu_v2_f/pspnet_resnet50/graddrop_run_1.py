# This file is automatically generated by `./configs/benchmarks/multi_task_learning/gen_multi_task_learning.py`.
# Please do not attempt to modify manually.
import torch
import schedulers


config = {
    'runner': None,
    'work_dir': None,
    'epochs': 100,
    # seeds
    'init_seed': None,
    'train_seeds': None,
    'val_seeds': None,
    'test_seed': None,
    # dataset config
    'train_dataset': None,
    'train_dataloader': None,
    'val_dataset': None,
    'val_dataloader': None,
    'test_dataset': None,
    'test_dataloader': None,
    'criterion': None,
    'metric': None,
    # model config
    'model': None,
    # optimizer config
    'optimizer': None,
    'scheduler': {
        'class': torch.optim.lr_scheduler.LambdaLR,
        'args': {
            'lr_lambda': {
                'class': schedulers.lr_lambdas.WarmupLambda,
                'args': {},
            },
        },
    },
}

from runners import SupervisedMultiTaskTrainer
config['runner'] = SupervisedMultiTaskTrainer

# dataset config
from configs.common.datasets.multi_task_learning.nyu_v2_f import config as dataset_config
config.update(dataset_config)

# model config
from configs.common.models.multi_task_learning.nyu_v2_f.pspnet_resnet50 import model_config_all_tasks as model_config
config['model'] = model_config

# optimizer config
from configs.common.optimizers.multi_task_learning.graddrop import optimizer_config
from configs.common.optimizers.standard import adam_optimizer_config
optimizer_config['args']['optimizer_config'] = adam_optimizer_config
optimizer_config['args']['per_layer'] = False
config['optimizer'] = optimizer_config

# seeds
config['init_seed'] = 77776974
config['train_seeds'] = [63035009, 23166536, 51576180, 72840179, 27281073, 57772391, 2535869, 39059435, 71563509, 26587783, 25065026, 72276042, 69521651, 84922372, 43207580, 67058996, 59532934, 30956158, 21509228, 62675320, 95368357, 26690327, 47156806, 21279241, 46069921, 79027446, 90462305, 61140703, 95903621, 82515840, 54453246, 89288968, 22228245, 91360636, 49393046, 96976020, 53941387, 23605599, 66866364, 47753280, 64253231, 76056945, 34917921, 56092584, 84286853, 54841293, 3269260, 13743134, 84586483, 90796416, 16058696, 8711425, 33341836, 54358659, 97791305, 91895381, 86326784, 97118970, 57517232, 58610786, 78753666, 30562307, 65895097, 49617434, 5104918, 28313814, 62620977, 19241089, 83214294, 50109316, 55114201, 15567194, 77701173, 49412034, 17591120, 54427308, 80018399, 99550165, 56841849, 79960399, 4698327, 48686053, 38196570, 65916063, 87790236, 63000418, 43498779, 33843844, 72910688, 43018183, 92468156, 33446500, 31109778, 42612780, 34282492, 15750749, 80111853, 49738764, 82487283, 60798712]
config['val_seeds'] = [86329614, 94666808, 26873311, 22758373, 74820257, 40259151, 97379414, 60583314, 10541432, 90318844, 14706957, 30129851, 3526738, 38525886, 30073707, 63052058, 7716645, 99503516, 58093698, 71433271, 31661314, 44396449, 99041156, 36123359, 43855720, 13542736, 43100836, 72349070, 31516276, 50182442, 73398986, 13051777, 24837595, 65119317, 91162754, 47959324, 23466305, 56019512, 83179791, 94712826, 40937301, 22111894, 6384802, 87184502, 76889262, 838723, 99674424, 51296434, 91047189, 8360026, 68252451, 34973600, 99568461, 66734092, 63910479, 805425, 30219573, 91363046, 69638607, 17196930, 87505771, 68925269, 90947347, 60037598, 99164919, 38847388, 94551773, 71792519, 11212689, 1840181, 20583323, 48415190, 85841215, 48747575, 26960381, 62475439, 70122595, 3526237, 50907841, 36825740, 56081703, 31762343, 35185175, 27414935, 75368261, 93476026, 97807837, 45120819, 79372943, 23987660, 32941785, 32849225, 6393385, 87222296, 84686784, 17495538, 98005244, 23565716, 71041938, 84310249]
config['test_seed'] = 53730625

# work dir
config['work_dir'] = "./logs/benchmarks/multi_task_learning/nyu_v2_f/pspnet_resnet50/graddrop_run_1"
