# This file is automatically generated by `./configs/benchmarks/multi_task_learning/gen_multi_task_learning.py`.
# Please do not attempt to modify manually.
import torch
import schedulers


config = {
    'runner': None,
    'work_dir': None,
    'epochs': 100,
    # seeds
    'init_seed': None,
    'train_seeds': None,
    'val_seeds': None,
    'test_seed': None,
    # dataset config
    'train_dataset': None,
    'train_dataloader': None,
    'val_dataset': None,
    'val_dataloader': None,
    'test_dataset': None,
    'test_dataloader': None,
    'criterion': None,
    'metric': None,
    # model config
    'model': None,
    # optimizer config
    'optimizer': None,
    'scheduler': {
        'class': torch.optim.lr_scheduler.LambdaLR,
        'args': {
            'lr_lambda': {
                'class': schedulers.lr_lambdas.WarmupLambda,
                'args': {},
            },
        },
    },
}

from runners import SupervisedMultiTaskTrainer
config['runner'] = SupervisedMultiTaskTrainer

# dataset config
from configs.common.datasets.multi_task_learning.nyu_v2_f import config as dataset_config
config.update(dataset_config)

# model config
from configs.common.models.multi_task_learning.nyu_v2_f.pspnet_resnet50 import model_config_all_tasks as model_config
config['model'] = model_config

# optimizer config
from configs.common.optimizers.multi_task_learning.graddrop import optimizer_config
from configs.common.optimizers.standard import adam_optimizer_config
optimizer_config['args']['optimizer_config'] = adam_optimizer_config
optimizer_config['args']['per_layer'] = False
config['optimizer'] = optimizer_config

# seeds
config['init_seed'] = 3244685
config['train_seeds'] = [45785457, 88913962, 16723034, 71070193, 58415083, 44620050, 54189288, 61781373, 79012417, 85756351, 89973364, 29153290, 81810382, 97442482, 45466136, 91912635, 72281421, 70917681, 905320, 93930833, 2042293, 38388230, 3084645, 88629205, 83944128, 87424315, 43997308, 49048455, 62722344, 33476076, 14125827, 12133292, 92062732, 71694967, 45116492, 74011149, 88630564, 22371945, 63372684, 55296639, 35799989, 57025910, 28069794, 15996868, 58330981, 56495986, 33710593, 89733064, 85847692, 52092364, 48358694, 96732268, 96555946, 17347793, 15947851, 66871853, 74863556, 94178777, 56184562, 53565586, 84004768, 32611114, 63385429, 88438507, 83150958, 51957581, 62252196, 16488128, 39172314, 14707777, 97135599, 89333423, 11837874, 39489417, 79934730, 4849791, 98336430, 69287347, 65756769, 91165, 69857877, 90329167, 13766126, 61332551, 61442838, 80825344, 51531096, 97589116, 12531394, 46918482, 79117252, 90545705, 43622289, 70335742, 46621586, 11078806, 19578643, 88901824, 1420425, 60243632]
config['val_seeds'] = [21924959, 53264543, 75331911, 54881806, 83417498, 76240985, 56516594, 76974098, 9522200, 35906841, 33850585, 12779886, 53380733, 31285711, 7406529, 29539953, 59219234, 93001837, 48037146, 7248863, 17745408, 6585537, 6460298, 16830516, 36661858, 57193822, 55268506, 12933607, 70303331, 37671846, 84926340, 2093061, 90060771, 40703716, 57403056, 12843196, 88326565, 1650630, 86152061, 8662322, 87491578, 4338929, 39970875, 96108838, 78431576, 25514386, 4583227, 98582064, 94599557, 4897936, 75510328, 11645368, 11607519, 36453990, 97690696, 98574149, 67746306, 68787719, 65903467, 76166128, 62644439, 15280356, 98501467, 23049958, 54606017, 35227913, 21247333, 55875226, 24369683, 20778133, 97141711, 2680120, 68566807, 21886958, 86772037, 10147250, 56470998, 70368789, 17103866, 67624208, 27070237, 79145647, 34763616, 19527428, 98425818, 47529396, 86932203, 93360565, 24890404, 29255727, 8967188, 13637968, 67849647, 47704940, 40247433, 97239847, 55162635, 13477176, 45604474, 15872032]
config['test_seed'] = 89300079

# work dir
config['work_dir'] = "./logs/benchmarks/multi_task_learning/nyu_v2_f/pspnet_resnet50/graddrop_run_2"
