# This file is automatically generated by `./configs/benchmarks/multi_task_learning/gen_multi_task_learning.py`.
# Please do not attempt to modify manually.
import torch
import schedulers


config = {
    'runner': None,
    'work_dir': None,
    'epochs': 100,
    # seeds
    'init_seed': None,
    'train_seeds': None,
    'val_seeds': None,
    'test_seed': None,
    # dataset config
    'train_dataset': None,
    'train_dataloader': None,
    'val_dataset': None,
    'val_dataloader': None,
    'test_dataset': None,
    'test_dataloader': None,
    'criterion': None,
    'metric': None,
    # model config
    'model': None,
    # optimizer config
    'optimizer': None,
    'scheduler': {
        'class': torch.optim.lr_scheduler.LambdaLR,
        'args': {
            'lr_lambda': {
                'class': schedulers.lr_lambdas.WarmupLambda,
                'args': {},
            },
        },
    },
}

from runners import SupervisedMultiTaskTrainer
config['runner'] = SupervisedMultiTaskTrainer

# dataset config
from configs.common.datasets.multi_task_learning.nyu_v2_f import config as dataset_config
config.update(dataset_config)

# model config
from configs.common.models.multi_task_learning.nyu_v2_f.pspnet_resnet50 import model_config_all_tasks as model_config
config['model'] = model_config

# optimizer config
from configs.common.optimizers.multi_task_learning.graddrop import optimizer_config
from configs.common.optimizers.standard import adam_optimizer_config
optimizer_config['args']['optimizer_config'] = adam_optimizer_config
optimizer_config['args']['per_layer'] = False
config['optimizer'] = optimizer_config

# seeds
config['init_seed'] = 31873391
config['train_seeds'] = [39751611, 547122, 16665840, 67481389, 16359820, 77308848, 71955365, 24338572, 53377769, 16962396, 20262826, 63814687, 65722887, 99128304, 93263176, 23697888, 2359933, 55737795, 23340520, 12458637, 3584110, 65376065, 30631703, 93859513, 50146372, 8259390, 5740677, 21911126, 94636645, 89704617, 94301370, 34176764, 88286784, 78934457, 21044038, 49997759, 41482454, 19077716, 19469025, 73120313, 23590601, 74749876, 70928488, 383335, 72349805, 2786998, 83084047, 33510441, 77476806, 30596063, 54840208, 10950879, 79394169, 85049661, 82998972, 92603399, 43905703, 12430493, 51073570, 55651980, 75067692, 59738878, 81759798, 31654675, 49715816, 20395509, 46872879, 27598597, 70699981, 58577464, 58451767, 51839451, 24837234, 70930907, 89252900, 58608777, 45942200, 48490093, 73147913, 36717444, 10542988, 67408959, 37293883, 63975417, 34211543, 37791881, 60263860, 58791909, 80867545, 16577238, 8846549, 85220057, 30248652, 11045266, 6901922, 58119444, 23958996, 23294097, 22719287, 92789840]
config['val_seeds'] = [21781918, 92674803, 13958589, 11469683, 5265849, 47222771, 66569363, 29876740, 31901957, 76953914, 52544026, 91445444, 36997080, 80127204, 63052031, 35666066, 50847608, 33892801, 34828786, 53962703, 73600185, 5450616, 61629328, 82523598, 22060788, 80942297, 24670195, 59084857, 4537752, 53040798, 94888055, 24096877, 12166609, 42567692, 86157403, 24101501, 28503830, 40392715, 18486512, 46679078, 85278212, 32723233, 7371881, 74952919, 3745568, 24437282, 96906017, 45130871, 79853123, 52054730, 32023444, 92822468, 67234577, 85315902, 86229170, 77854372, 24439872, 29498212, 89416294, 65718764, 26933963, 89135846, 63319113, 36795386, 32503871, 99472176, 85891863, 13517606, 48444984, 81068928, 48902962, 91795088, 40889970, 94458991, 7984984, 77430997, 18211767, 87425420, 38020943, 50389481, 67715529, 75555917, 37884821, 92722277, 39813502, 65563086, 19256105, 38117673, 75650913, 52256277, 50473609, 30466688, 83174721, 28466902, 20840, 31402250, 75996893, 13981142, 82276345, 75021107]
config['test_seed'] = 71521933

# work dir
config['work_dir'] = "./logs/benchmarks/multi_task_learning/nyu_v2_f/pspnet_resnet50/graddrop_run_0"
