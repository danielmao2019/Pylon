# This file is automatically generated by `./configs/benchmarks/multi_task_learning/gen_multi_task_learning.py`.
# Please do not attempt to modify manually.
import torch
import schedulers


config = {
    'runner': None,
    'work_dir': None,
    'epochs': 100,
    # seeds
    'init_seed': None,
    'train_seeds': None,
    'val_seeds': None,
    'test_seed': None,
    # dataset config
    'train_dataset': None,
    'train_dataloader': None,
    'val_dataset': None,
    'val_dataloader': None,
    'test_dataset': None,
    'test_dataloader': None,
    'criterion': None,
    'metric': None,
    # model config
    'model': None,
    # optimizer config
    'optimizer': None,
    'scheduler': {
        'class': torch.optim.lr_scheduler.LambdaLR,
        'args': {
            'lr_lambda': {
                'class': schedulers.lr_lambdas.WarmupLambda,
                'args': {},
            },
        },
    },
}

from runners import SupervisedMultiTaskTrainer
config['runner'] = SupervisedMultiTaskTrainer

# dataset config
from configs.common.datasets.multi_task_learning.nyu_v2_f import config as dataset_config
config.update(dataset_config)

# model config
from configs.common.models.multi_task_learning.nyu_v2_f.pspnet_resnet50 import model_config_all_tasks as model_config
config['model'] = model_config

# optimizer config
from configs.common.optimizers.multi_task_learning.alignedmtl_ub import optimizer_config
from configs.common.optimizers.standard import adam_optimizer_config
optimizer_config['args']['optimizer_config'] = adam_optimizer_config
optimizer_config['args']['per_layer'] = False
config['optimizer'] = optimizer_config

# seeds
config['init_seed'] = 7294676
config['train_seeds'] = [84698108, 43546060, 13886971, 54248953, 27901062, 78831532, 13906604, 29610857, 41605234, 97914806, 53682986, 78224296, 58879177, 7643415, 12362532, 98463536, 25952480, 2103499, 95623778, 41925160, 19060236, 61784073, 90650436, 17062219, 89679297, 30058365, 61904435, 46463835, 28981889, 3315944, 37130853, 74623576, 99702776, 27198767, 87554822, 18274703, 26558162, 87445098, 95986612, 29020521, 39750235, 62367175, 61243921, 74530422, 56239903, 17737201, 66970363, 81943055, 4935268, 34109561, 31663882, 85182037, 81170289, 82109140, 15316921, 80021949, 48280582, 84176531, 27280351, 40348318, 62270362, 40839769, 23589121, 56398811, 27660405, 66667919, 8929588, 7923881, 70057683, 89149472, 18353881, 5565979, 2466678, 37333048, 31264783, 71449967, 75018578, 27520826, 66648906, 6184449, 56218474, 39661718, 42659561, 41668142, 31736998, 69434398, 76627729, 3299433, 41303816, 15238048, 66187649, 51403567, 45143093, 57244574, 57650567, 9752286, 33541900, 28661981, 90541653, 4682831]
config['val_seeds'] = [79931699, 35391266, 67237023, 86234733, 48394847, 12345994, 91024050, 16373692, 77765482, 5838723, 81653583, 18941495, 3375336, 84152697, 85906678, 3354727, 12221616, 19321833, 70448955, 48030140, 87417549, 75580058, 83295237, 60511967, 73755331, 53324149, 92155052, 79423225, 48610174, 4085193, 76093872, 66361704, 69207235, 99470261, 4545341, 76661533, 6450837, 56103483, 37506597, 43460402, 13140687, 98831565, 46712002, 91917727, 49468947, 61935716, 43808368, 62663452, 74328492, 76045755, 32474518, 7214868, 37826500, 50681369, 44204749, 13290915, 97351882, 71886882, 8427714, 51290767, 5615196, 10222669, 8587369, 97835231, 26737911, 75973030, 13069517, 99287546, 35341689, 81758217, 69614664, 7660603, 8572326, 4484317, 78080882, 99376007, 20133485, 10437622, 37479537, 42372636, 67432289, 57771330, 36134512, 64076187, 60618953, 33465977, 16066677, 72846485, 80515765, 92921342, 79373120, 54427552, 38965142, 11438708, 83310597, 60653597, 13919133, 83455385, 28215422, 2854299]
config['test_seed'] = 65435109

# work dir
config['work_dir'] = "./logs/benchmarks/multi_task_learning/nyu_v2_f/pspnet_resnet50/alignedmtl_ub_run_1"
