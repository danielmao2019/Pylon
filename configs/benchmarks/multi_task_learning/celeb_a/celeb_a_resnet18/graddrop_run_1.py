# This file is automatically generated by `./configs/benchmarks/multi_task_learning/gen_multi_task_learning.py`.
# Please do not attempt to modify manually.
import torch
import schedulers


config = {
    'runner': None,
    'work_dir': None,
    'epochs': 100,
    # seeds
    'init_seed': None,
    'train_seeds': None,
    'val_seeds': None,
    'test_seed': None,
    # dataset config
    'train_dataset': None,
    'train_dataloader': None,
    'val_dataset': None,
    'val_dataloader': None,
    'test_dataset': None,
    'test_dataloader': None,
    'criterion': None,
    'metric': None,
    # model config
    'model': None,
    # optimizer config
    'optimizer': None,
    'scheduler': {
        'class': torch.optim.lr_scheduler.LambdaLR,
        'args': {
            'lr_lambda': {
                'class': schedulers.lr_lambdas.WarmupLambda,
                'args': {},
            },
        },
    },
}

from runners import SupervisedMultiTaskTrainer
config['runner'] = SupervisedMultiTaskTrainer

# dataset config
from configs.common.datasets.multi_task_learning.celeb_a import config as dataset_config
config.update(dataset_config)

# model config
from configs.common.models.multi_task_learning.celeb_a.celeb_a_resnet18 import model_config_all_tasks as model_config
config['model'] = model_config

# optimizer config
from configs.common.optimizers.multi_task_learning.graddrop import optimizer_config
from configs.common.optimizers.standard import adam_optimizer_config
optimizer_config['args']['optimizer_config'] = adam_optimizer_config
optimizer_config['args']['per_layer'] = False
config['optimizer'] = optimizer_config

# seeds
config['init_seed'] = 97309104
config['train_seeds'] = [32093365, 53123179, 28230851, 13559451, 20239991, 15742264, 33613946, 11706645, 70720477, 68569140, 12176823, 82313258, 2335625, 64762229, 71102810, 70261973, 29095062, 77355834, 79682684, 77054766, 88993125, 45922450, 30551981, 20764707, 35811778, 2747593, 11000425, 57872191, 2508648, 10914000, 47631429, 25039623, 26699387, 2490529, 58155057, 94129002, 78412050, 58651257, 22114640, 76524731, 47551676, 68264490, 88826775, 64155562, 19624894, 14246759, 36747897, 62874346, 86245800, 7266979, 14324358, 88907110, 67038928, 71585272, 87325665, 16139378, 89598385, 97946452, 159807, 52552086, 22727751, 2406280, 7646424, 74252777, 29742937, 3360421, 14819084, 85393693, 20088825, 75344348, 20884041, 63590638, 9992553, 11200029, 24082158, 36919500, 59509570, 6408140, 93919713, 50197537, 10249307, 31374585, 71212303, 92943101, 54727059, 34476955, 15303229, 79795311, 6853409, 62654377, 98003111, 62147775, 94289483, 41912235, 46877395, 67713647, 87808012, 38055694, 79228307, 9133173]
config['val_seeds'] = [84902849, 52159578, 81121356, 44188085, 56989865, 73179328, 17081772, 4722413, 66593516, 9918016, 81970966, 1276738, 96912250, 23204127, 73007593, 28526317, 64588945, 84888510, 71595070, 40255088, 83332011, 51486625, 2942461, 50759683, 24734816, 20132090, 8650679, 34959915, 2857737, 75188254, 56084508, 57108492, 8617346, 58871049, 7688168, 33958105, 91084881, 89033756, 3553646, 48550034, 75363954, 11026105, 90725932, 39009395, 31817053, 55446, 18835723, 84460577, 48222993, 23975275, 89334214, 32711869, 12328596, 21951231, 27822419, 36835995, 19088248, 47871716, 70163187, 10238324, 62433953, 594791, 26586928, 24810960, 68196298, 76017781, 96878954, 79268002, 46718417, 91495958, 31243909, 51239444, 43449861, 40793955, 99624557, 93063064, 36723626, 8724741, 50740731, 52281433, 82928076, 68166768, 8402220, 50585765, 6322247, 88857899, 2666741, 74178541, 85053103, 41662624, 55830899, 22949332, 13386559, 45196795, 24310290, 20812012, 44949080, 74249080, 51880047, 49886245]
config['test_seed'] = 54561557

# work dir
config['work_dir'] = "./logs/benchmarks/multi_task_learning/celeb_a/celeb_a_resnet18/graddrop_run_1"
