# This file is automatically generated by `./configs/benchmarks/multi_task_learning/gen_multi_task_learning.py`.
# Please do not attempt to modify manually.
import torch
import schedulers


config = {
    'runner': None,
    'work_dir': None,
    'epochs': 100,
    # seeds
    'init_seed': None,
    'train_seeds': None,
    'val_seeds': None,
    'test_seed': None,
    # dataset config
    'train_dataset': None,
    'train_dataloader': None,
    'val_dataset': None,
    'val_dataloader': None,
    'test_dataset': None,
    'test_dataloader': None,
    'criterion': None,
    'metric': None,
    # model config
    'model': None,
    # optimizer config
    'optimizer': None,
    'scheduler': {
        'class': torch.optim.lr_scheduler.LambdaLR,
        'args': {
            'lr_lambda': {
                'class': schedulers.lr_lambdas.WarmupLambda,
                'args': {},
            },
        },
    },
}

from runners import SupervisedMultiTaskTrainer
config['runner'] = SupervisedMultiTaskTrainer

# dataset config
from configs.common.datasets.multi_task_learning.celeb_a import config as dataset_config
config.update(dataset_config)

# model config
from configs.common.models.multi_task_learning.celeb_a.celeb_a_resnet18 import model_config_all_tasks as model_config
config['model'] = model_config

# optimizer config
from configs.common.optimizers.multi_task_learning.mgda import optimizer_config
from configs.common.optimizers.standard import adam_optimizer_config
optimizer_config['args']['optimizer_config'] = adam_optimizer_config
optimizer_config['args']['per_layer'] = False
config['optimizer'] = optimizer_config

# seeds
config['init_seed'] = 41962201
config['train_seeds'] = [31285632, 62746610, 24015104, 74001055, 14414381, 97963728, 13196532, 8039263, 18345155, 13131541, 38953579, 59056485, 13708270, 21011540, 40929098, 92491141, 72042763, 12176201, 98525687, 32815994, 103882, 10607278, 37900915, 50918045, 63418077, 75687992, 88914846, 4237026, 42583336, 34056140, 75451084, 18056541, 60189092, 39841693, 70717004, 91232482, 86906983, 32904723, 68215250, 35470614, 41565040, 70209708, 72970002, 72939253, 28323022, 66711907, 65868221, 25815664, 13844588, 23746473, 76508248, 81378165, 89019392, 53149709, 56432187, 69594013, 24331043, 9943308, 60856901, 38958623, 26006117, 51056627, 7163570, 13210984, 9321615, 33095216, 99805374, 10031516, 37073696, 8436745, 47619404, 12567787, 86768489, 96146277, 36093000, 88208283, 67160435, 80078241, 50736973, 46279448, 16196927, 10388569, 88672819, 55441222, 35803683, 98703204, 75739109, 64850824, 6530291, 61415397, 58969275, 88198426, 57915084, 74900112, 94890180, 93220817, 79027528, 20896262, 12659376, 12230478]
config['val_seeds'] = [81475626, 10282618, 70434168, 77895594, 33661486, 96470998, 71641922, 12874511, 66553398, 52067359, 85323973, 28945203, 32807944, 68935232, 8019345, 81226613, 39164561, 33115523, 16067295, 71033706, 88258240, 59342812, 29718909, 82979884, 82411133, 51962386, 31517026, 76122270, 10048254, 35731935, 34083207, 33240872, 49597638, 11599912, 15210009, 64523903, 54334558, 33288313, 43710316, 96323082, 30488498, 6478609, 59015477, 71832552, 1285937, 89308719, 22599452, 64651300, 7482249, 24062013, 92314908, 46431255, 38085847, 31069944, 64361967, 77705606, 21552453, 9354259, 94428379, 55994488, 55735051, 19337674, 35026915, 17334674, 42786634, 77067169, 1148368, 87919860, 74253994, 32851731, 52023286, 56605744, 63325389, 27519092, 37746997, 68253239, 12512903, 49226163, 8021789, 85497064, 93855546, 99109127, 45889179, 28759777, 23101452, 24817821, 14079358, 42429927, 56009747, 57909845, 75108666, 4374102, 63487005, 4198460, 66527767, 13326224, 53768872, 50550597, 28827093, 25299654]
config['test_seed'] = 78633606

# work dir
config['work_dir'] = "./logs/benchmarks/multi_task_learning/celeb_a/celeb_a_resnet18/mgda_run_0"
