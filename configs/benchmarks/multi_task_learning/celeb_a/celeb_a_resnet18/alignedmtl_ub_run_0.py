# This file is automatically generated by `./configs/benchmarks/multi_task_learning/gen_multi_task_learning.py`.
# Please do not attempt to modify manually.
import torch
import schedulers


config = {
    'runner': None,
    'work_dir': None,
    'epochs': 100,
    # seeds
    'init_seed': None,
    'train_seeds': None,
    'val_seeds': None,
    'test_seed': None,
    # dataset config
    'train_dataset': None,
    'train_dataloader': None,
    'val_dataset': None,
    'val_dataloader': None,
    'test_dataset': None,
    'test_dataloader': None,
    'criterion': None,
    'metric': None,
    # model config
    'model': None,
    # optimizer config
    'optimizer': None,
    'scheduler': {
        'class': torch.optim.lr_scheduler.LambdaLR,
        'args': {
            'lr_lambda': {
                'class': schedulers.lr_lambdas.WarmupLambda,
                'args': {},
            },
        },
    },
}

from runners import SupervisedMultiTaskTrainer
config['runner'] = SupervisedMultiTaskTrainer

# dataset config
from configs.common.datasets.multi_task_learning.celeb_a import config as dataset_config
config.update(dataset_config)

# model config
from configs.common.models.multi_task_learning.celeb_a.celeb_a_resnet18 import model_config_all_tasks as model_config
config['model'] = model_config

# optimizer config
from configs.common.optimizers.multi_task_learning.alignedmtl_ub import optimizer_config
from configs.common.optimizers.standard import adam_optimizer_config
optimizer_config['args']['optimizer_config'] = adam_optimizer_config
optimizer_config['args']['per_layer'] = False
config['optimizer'] = optimizer_config

# seeds
config['init_seed'] = 92369765
config['train_seeds'] = [69999852, 57447660, 17533827, 57600405, 60255527, 73637721, 51557274, 33805982, 35879783, 89923505, 54495793, 38811217, 80613647, 77445631, 41118952, 525959, 11624807, 51862544, 69874165, 6091796, 906265, 7860791, 22166760, 60768439, 19212972, 15934739, 2409183, 43916936, 17599734, 9186518, 28416026, 40684299, 74035134, 17685821, 8395670, 33777676, 76189292, 28114686, 32297224, 59768543, 52454289, 37948942, 54069642, 61177643, 18082420, 73293914, 56818970, 96877121, 3186062, 41211780, 45135325, 83774306, 70465361, 75289915, 63226866, 3325654, 88534066, 50940823, 57894514, 24595082, 95729894, 91583171, 98364009, 83004236, 68515726, 56367859, 17502610, 28766197, 13037573, 24366887, 8927453, 11633061, 91035265, 19052433, 89373436, 74667595, 82551550, 73901896, 72501627, 35685711, 70802521, 59812127, 49027552, 1192590, 50608979, 17927481, 80630539, 65173888, 91311251, 93362020, 99070032, 58854738, 35897121, 59257766, 75994029, 52656452, 10686216, 15045453, 18415807, 94022641]
config['val_seeds'] = [71494970, 26095436, 47009800, 91240251, 33478123, 49797822, 2888804, 8589597, 77872268, 58309977, 71064858, 90614655, 96894843, 85252444, 96595755, 96739211, 76227596, 70033066, 8003787, 13917003, 30858883, 66354608, 19663637, 45541376, 81391015, 4050918, 11291955, 91318317, 7045740, 44430917, 71845992, 71793889, 77984210, 9775222, 45766513, 9085498, 52417646, 89808320, 6216008, 59058926, 23717756, 66330447, 52511434, 29291675, 41492455, 70101312, 30777016, 53166413, 93045469, 16612803, 30510573, 45422682, 94553517, 93679212, 65567639, 97717463, 10506134, 92801239, 19335593, 20773933, 99824459, 82051047, 25411179, 28123646, 13676932, 72026781, 75394481, 80900604, 87440810, 81656655, 87683593, 86142658, 38567650, 49993685, 57674050, 97129713, 88259417, 23596036, 12688403, 30463417, 44168466, 63817849, 90422146, 68613517, 16982102, 62681106, 7033136, 42659630, 48715756, 80925872, 99843506, 2284717, 43638589, 46308105, 55242442, 82589661, 55125961, 6748686, 39884386, 10142848]
config['test_seed'] = 45813563

# work dir
config['work_dir'] = "./logs/benchmarks/multi_task_learning/celeb_a/celeb_a_resnet18/alignedmtl_ub_run_0"
