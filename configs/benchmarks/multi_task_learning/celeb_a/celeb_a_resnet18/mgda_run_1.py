# This file is automatically generated by `./configs/benchmarks/multi_task_learning/gen_multi_task_learning.py`.
# Please do not attempt to modify manually.
import torch
import schedulers


config = {
    'runner': None,
    'work_dir': None,
    'epochs': 100,
    # seeds
    'init_seed': None,
    'train_seeds': None,
    'val_seeds': None,
    'test_seed': None,
    # dataset config
    'train_dataset': None,
    'train_dataloader': None,
    'val_dataset': None,
    'val_dataloader': None,
    'test_dataset': None,
    'test_dataloader': None,
    'criterion': None,
    'metric': None,
    # model config
    'model': None,
    # optimizer config
    'optimizer': None,
    'scheduler': {
        'class': torch.optim.lr_scheduler.LambdaLR,
        'args': {
            'lr_lambda': {
                'class': schedulers.lr_lambdas.WarmupLambda,
                'args': {},
            },
        },
    },
}

from runners import SupervisedMultiTaskTrainer
config['runner'] = SupervisedMultiTaskTrainer

# dataset config
from configs.common.datasets.multi_task_learning.celeb_a import config as dataset_config
config.update(dataset_config)

# model config
from configs.common.models.multi_task_learning.celeb_a.celeb_a_resnet18 import model_config_all_tasks as model_config
config['model'] = model_config

# optimizer config
from configs.common.optimizers.multi_task_learning.mgda import optimizer_config
from configs.common.optimizers.standard import adam_optimizer_config
optimizer_config['args']['optimizer_config'] = adam_optimizer_config
optimizer_config['args']['per_layer'] = False
config['optimizer'] = optimizer_config

# seeds
config['init_seed'] = 35859059
config['train_seeds'] = [91184742, 66695368, 33331203, 13771732, 51125974, 81485069, 99188202, 61480417, 30718587, 15207449, 7246158, 3297942, 21582139, 57429807, 46613613, 33334773, 94660476, 52660738, 37854754, 92028663, 94471303, 96265677, 75290855, 19101000, 28952095, 85126387, 74973252, 49356226, 7500084, 42035060, 94592354, 17985135, 63229111, 15268560, 83329971, 99312902, 49131963, 1089408, 63357466, 91726635, 9639854, 8235647, 61856627, 6431623, 1033327, 46716897, 81272323, 19701365, 76928548, 47873679, 51091088, 98455410, 87701108, 41513697, 39465173, 64085243, 74984327, 62063, 48665742, 89666687, 48317842, 88768341, 27372977, 6097810, 84617866, 21002002, 39268937, 44845494, 89121727, 53414603, 57554289, 65744771, 1068530, 95835626, 28766714, 78319524, 22312660, 85094096, 29539467, 96738595, 83034814, 20111101, 94940915, 38743913, 61214586, 87355888, 66733540, 40785565, 26313027, 69137572, 12511684, 94607879, 79905684, 76398191, 29335633, 95706567, 97875337, 53285108, 26295528, 6699102]
config['val_seeds'] = [54780431, 95162130, 79639971, 58101977, 47160946, 33562262, 53594300, 99555735, 85780573, 19438036, 54889303, 20462854, 36917304, 64836353, 3261008, 32562006, 80135209, 19411014, 425369, 85881774, 2251016, 67959957, 98859021, 63898257, 29407019, 97635281, 6171341, 19587485, 34335455, 40654512, 33928251, 9164172, 47794381, 40211211, 49749223, 70508068, 28662736, 60085655, 77377458, 22373950, 15468799, 29169103, 15719331, 20659640, 58842443, 28587471, 84689274, 80485103, 31681744, 88341848, 86627291, 78993723, 95417964, 81665841, 22383661, 16920249, 11965024, 56019002, 60358684, 80165997, 54720212, 73883295, 31079605, 20325148, 87589582, 65081061, 42846673, 67914737, 11290948, 86346514, 82397352, 82022831, 85339731, 10463583, 20728684, 1194020, 4389863, 32600527, 63436528, 21737550, 35031004, 96331319, 548545, 84469155, 24516831, 26519315, 87170920, 13872155, 90103097, 64493493, 74615484, 32721738, 66113421, 59396356, 37808861, 41676652, 48597811, 85925732, 44340431, 52129526]
config['test_seed'] = 63532803

# work dir
config['work_dir'] = "./logs/benchmarks/multi_task_learning/celeb_a/celeb_a_resnet18/mgda_run_1"
