# This file is automatically generated by `./configs/benchmarks/change_detection/gen_bi_temporal.py`.
# Please do not attempt to modify manually.
from torch import Tensor
from torch.optim.lr_scheduler import PolynomialLR
from torch.optim.sgd import SGD
from torch.utils.data.dataloader import DataLoader
from torchvision.transforms.transforms import ColorJitter
from criteria.vision_2d.dense_prediction.dense_classification.semantic_segmentation import SemanticSegmentationCriterion
from data.collators.base_collator import BaseCollator
from data.datasets.change_detection_datasets.bi_temporal.air_change_dataset import AirChangeDataset
from data.transforms.compose import Compose
from data.transforms.randomize import Randomize
from data.transforms.torchvision_wrapper import TorchvisionWrapper
from data.transforms.vision_2d.crop.random_crop import RandomCrop
from data.transforms.vision_2d.flip import Flip
from data.transforms.vision_2d.random_rotation import RandomRotation
from data.transforms.vision_2d.resize.maps import ResizeMaps
from metrics.vision_2d.semantic_segmentation_metric import SemanticSegmentationMetric
from models.change_detection.changer.changer_model import Changer
from models.change_detection.changer.modules.changer_decoder import ChangerDecoder
from models.change_detection.changer.modules.interaction_layer import ChannelExchange, SpatialExchange
from models.change_detection.changer.modules.interaction_resnet import IA_ResNetV1c
from optimizers.single_task_optimizer import SingleTaskOptimizer
from runners.supervised_single_task_trainer import SupervisedSingleTaskTrainer


config = {
    'runner': SupervisedSingleTaskTrainer,
    'work_dir': './logs/benchmarks/change_detection/air_change/Changer-r18_run_0',
    'epochs': 100,
    'init_seed': 35233616,
    'train_seeds': [2467932, 71653508, 89038934, 28225460, 23157678, 44873194, 60964475, 89388874, 14816166, 54832520, 8165093, 33277760, 61635259, 49444977, 55482934, 88964142, 10918862, 86306381, 94082857, 3655781, 75511618, 24204803, 57153159, 19273340, 18783255, 79741505, 78086081, 66754161, 43648997, 87658878, 72574246, 83178250, 54136013, 50182130, 19414550, 93566054, 90212863, 52526555, 89900632, 14504956, 86364384, 53767932, 56235194, 13983974, 33371009, 69045602, 16449363, 38450798, 5206622, 31729985, 45651219, 82516209, 54716703, 96391213, 60168952, 59719072, 34212020, 58873771, 39201199, 43222886, 95996563, 29722477, 6812576, 92803483, 60056783, 67771344, 26278648, 41162651, 37167230, 2201110, 12838479, 92462845, 7050295, 81027616, 94908565, 1354572, 18106173, 336908, 47673755, 9255367, 2898103, 51159023, 66090006, 22432581, 40293511, 99584499, 8827099, 91630051, 15314678, 81311807, 31369369, 45681387, 53856251, 41778663, 21464230, 29790837, 12720176, 97490224, 39410653, 89664105],
    'val_seeds': [63713585, 78858345, 68338303, 29660288, 87716425, 42293533, 31562173, 38929041, 21423025, 97753079, 70769410, 15216784, 35207762, 94185711, 90918481, 41392987, 85400266, 78795832, 82121120, 14181696, 83214049, 23878061, 79600735, 423237, 21684901, 3009281, 1455830, 35684362, 70513031, 46704116, 57581484, 94777951, 98260336, 95775165, 9180453, 82170213, 31993100, 14885479, 69088547, 92312805, 8844439, 9530070, 9809330, 21552864, 23707517, 25493155, 53412026, 47793537, 92748409, 60795547, 99306306, 34003015, 36186274, 1258934, 76996394, 805792, 27174352, 34412476, 62501325, 84696795, 66539626, 28854752, 34121712, 82150618, 28033923, 76682819, 68257550, 21205089, 1585301, 14563474, 77128294, 75472637, 80352940, 27097844, 28284538, 14528311, 89730505, 26449361, 74396935, 60851555, 31676067, 45163162, 79082994, 36981271, 70935149, 36286384, 65210588, 57566493, 51805808, 91682887, 73382358, 94474455, 56233689, 79606035, 73159186, 26276383, 81435584, 30900016, 46703291, 73215013],
    'test_seed': 67665476,
    'train_dataset': {
        'class': AirChangeDataset,
        'args': {
            'data_root': './data/datasets/soft_links/AirChange',
            'split': 'train',
            'transforms_cfg': {
                'class': Compose,
                'args': {
                    'transforms': [(
    {
            'class': ResizeMaps,
            'args': {
                'size': (256, 256),
                'interpolation': None,
                'antialias': True,
            },
        },
    [('inputs', 'img_1'), ('inputs', 'img_2'), ('labels', 'change_map')]
), (
    {
            'class': RandomRotation,
            'args': {
                'choices': [0, 90, 180, 270],
            },
        },
    [('inputs', 'img_1'), ('inputs', 'img_2'), ('labels', 'change_map')]
), (
    {
            'class': Randomize,
            'args': {
                'transform': {
                    'class': Flip,
                    'args': {
                        'axis': -1,
                    },
                },
                'p': 0.5,
            },
        },
    [('inputs', 'img_1'), ('inputs', 'img_2'), ('labels', 'change_map')]
), (
    {
            'class': Randomize,
            'args': {
                'transform': {
                    'class': Flip,
                    'args': {
                        'axis': -2,
                    },
                },
                'p': 0.5,
            },
        },
    [('inputs', 'img_1'), ('inputs', 'img_2'), ('labels', 'change_map')]
), (
    {
            'class': Randomize,
            'args': {
                'transform': {
                    'class': TorchvisionWrapper,
                    'args': {
                        'transform_class': ColorJitter,
                        'brightness': 0.5,
                        'contrast': 0.5,
                        'saturation': 0.5,
                    },
                },
                'p': 0.5,
            },
        },
    ('inputs', 'img_1')
), (
    {
            'class': Randomize,
            'args': {
                'transform': {
                    'class': TorchvisionWrapper,
                    'args': {
                        'transform_class': ColorJitter,
                        'brightness': 0.5,
                        'contrast': 0.5,
                        'saturation': 0.5,
                    },
                },
                'p': 0.5,
            },
        },
    ('inputs', 'img_2')
)],
                },
            },
        },
    },
    'train_dataloader': {
        'class': DataLoader,
        'args': {
            'batch_size': 4,
            'num_workers': 4,
            'collate_fn': {
                'class': BaseCollator,
                'args': {
                    'collators': {
                        'meta_info': {
                            'image_size': Tensor,
                            'crop_loc': Tensor,
                            'crop_size': Tensor,
                        },
                    },
                },
            },
        },
    },
    'criterion': {
        'class': SemanticSegmentationCriterion,
        'args': {
            'class_weights': (0.09632044285535812, 1.9036794900894165),
        },
    },
    'val_dataset': {
        'class': AirChangeDataset,
        'args': {
            'data_root': './data/datasets/soft_links/AirChange',
            'split': 'test',
            'transforms_cfg': {
                'class': Compose,
                'args': {
                    'transforms': [(
    {
            'class': RandomCrop,
            'args': {
                'size': (112, 112),
                'resize': (256, 256),
                'interpolation': None,
            },
        },
    [('inputs', 'img_1'), ('inputs', 'img_2'), ('labels', 'change_map')]
), (
    {
            'class': RandomRotation,
            'args': {
                'choices': [0, 90, 180, 270],
            },
        },
    [('inputs', 'img_1'), ('inputs', 'img_2'), ('labels', 'change_map')]
), (
    {
            'class': Randomize,
            'args': {
                'transform': {
                    'class': Flip,
                    'args': {
                        'axis': -1,
                    },
                },
                'p': 0.5,
            },
        },
    [('inputs', 'img_1'), ('inputs', 'img_2'), ('labels', 'change_map')]
), (
    {
            'class': Randomize,
            'args': {
                'transform': {
                    'class': Flip,
                    'args': {
                        'axis': -2,
                    },
                },
                'p': 0.5,
            },
        },
    [('inputs', 'img_1'), ('inputs', 'img_2'), ('labels', 'change_map')]
), (
    {
            'class': Randomize,
            'args': {
                'transform': {
                    'class': TorchvisionWrapper,
                    'args': {
                        'transform_class': ColorJitter,
                        'brightness': 0.5,
                        'contrast': 0.5,
                        'saturation': 0.5,
                    },
                },
                'p': 0.5,
            },
        },
    ('inputs', 'img_1')
), (
    {
            'class': Randomize,
            'args': {
                'transform': {
                    'class': TorchvisionWrapper,
                    'args': {
                        'transform_class': ColorJitter,
                        'brightness': 0.5,
                        'contrast': 0.5,
                        'saturation': 0.5,
                    },
                },
                'p': 0.5,
            },
        },
    ('inputs', 'img_2')
)],
                },
            },
        },
    },
    'val_dataloader': {
        'class': DataLoader,
        'args': {
            'batch_size': 1,
            'num_workers': 4,
            'collate_fn': {
                'class': BaseCollator,
                'args': {
                    'collators': {
                        'meta_info': {
                            'image_size': Tensor,
                            'crop_loc': Tensor,
                            'crop_size': Tensor,
                        },
                    },
                },
            },
        },
    },
    'test_dataset': None,
    'test_dataloader': None,
    'metric': {
        'class': SemanticSegmentationMetric,
        'args': {
            'num_classes': 2,
        },
    },
    'model': {
        'class': Changer,
        'args': {
            'encoder_cfg': {
                'class': IA_ResNetV1c,
                'args': {
                    'depth': 18,
                    'num_stages': 4,
                    'out_indices': (0, 1, 2, 3),
                    'dilations': (1, 1, 1, 1),
                    'strides': (1, 2, 2, 2),
                    'norm_cfg': {
                        'type': 'SyncBN',
                        'requires_grad': True,
                    },
                    'norm_eval': False,
                    'style': 'pytorch',
                    'contract_dilation': True,
                    'interaction_cfg': (
                        None,
                        {
                                                    'class': SpatialExchange,
                                                    'args': {
                                                        'p': 0.5,
                                                    },
                                                },
                        {
                                                    'class': ChannelExchange,
                                                    'args': {
                                                        'p': 0.5,
                                                    },
                                                },
                        {
                                                    'class': ChannelExchange,
                                                    'args': {
                                                        'p': 0.5,
                                                    },
                                                }
                    ),
                },
            },
            'decoder_cfg': {
                'class': ChangerDecoder,
                'args': {
                    'in_index': [0, 1, 2, 3],
                    'dropout_ratio': 0.1,
                    'num_classes': 2,
                    'norm_cfg': {
                        'type': 'SyncBN',
                        'requires_grad': True,
                    },
                    'align_corners': False,
                    'in_channels': [64, 128, 256, 512],
                    'channels': 128,
                    'sampler': {
                        'type': 'mmseg.OHEMPixelSampler',
                        'thresh': 0.7,
                        'min_kept': 100000,
                    },
                },
            },
        },
    },
    'optimizer': {
        'class': SingleTaskOptimizer,
        'args': {
            'optimizer_config': {
                'class': SGD,
                'args': {
                    'lr': 0.001,
                    'momentum': 0.9,
                    'weight_decay': 0.0001,
                },
            },
        },
    },
    'scheduler': {
        'class': PolynomialLR,
        'args': {
            'optimizer': None,
            'total_iters': None,
            'power': 0.9,
        },
    },
}
