# This file is automatically generated by `./configs/benchmarks/change_detection/gen_bi_temporal.py`.
# Please do not attempt to modify manually.
from torch import Tensor
from torch.optim.lr_scheduler import PolynomialLR
from torch.optim.sgd import SGD
from torch.utils.data.dataloader import DataLoader
from torchvision.transforms.transforms import ColorJitter
from criteria.vision_2d.dense_prediction.dense_classification.semantic_segmentation import SemanticSegmentationCriterion
from data.collators.base_collator import BaseCollator
from data.datasets.change_detection_datasets.bi_temporal.levir_cd_dataset import LevirCdDataset
from data.transforms.compose import Compose
from data.transforms.randomize import Randomize
from data.transforms.torchvision_wrapper import TorchvisionWrapper
from data.transforms.vision_2d.crop.random_crop import RandomCrop
from data.transforms.vision_2d.flip import Flip
from data.transforms.vision_2d.random_rotation import RandomRotation
from metrics.vision_2d.semantic_segmentation_metric import SemanticSegmentationMetric
from models.change_detection.changer.changer_model import Changer
from models.change_detection.changer.modules.changer_decoder import ChangerDecoder
from models.change_detection.changer.modules.interaction_layer import ChannelExchange, SpatialExchange
from models.change_detection.changer.modules.interaction_mit import IA_MixVisionTransformer
from optimizers.single_task_optimizer import SingleTaskOptimizer
from runners.trainers.supervised_single_task_trainer import SupervisedSingleTaskTrainer


config = {
    'runner': SupervisedSingleTaskTrainer,
    'work_dir': './logs/benchmarks/change_detection/levir_cd/Changer-mit-b1_run_0',
    'epochs': 100,
    'init_seed': 53713097,
    'train_seeds': [34279070, 53897920, 39693928, 4336976, 23803824, 10989567, 6682143, 41579915, 25445726, 81147502, 77326752, 34980779, 98542483, 68289203, 95000049, 64791564, 53609135, 72950139, 47652593, 68106224, 31083443, 23582177, 97807756, 40887431, 26929684, 12527722, 85887356, 16619112, 95675069, 80356914, 30240040, 28243334, 28801940, 52935593, 18373517, 22923944, 42016324, 81497797, 85879767, 54334668, 11849571, 39963528, 43582040, 37056473, 16725975, 76630881, 15929962, 3725021, 53125722, 97397116, 49977761, 1681067, 87347704, 7250933, 62432084, 13591622, 12865705, 19923582, 6757651, 21044509, 379509, 10928987, 13759673, 85435076, 62032030, 80584826, 49064666, 50385637, 92630429, 93190288, 48763125, 86051920, 75909114, 53541151, 51457900, 30933015, 77847328, 15841309, 37704240, 65421971, 77019999, 34464752, 34855464, 77116366, 52914035, 49529852, 8267001, 27276001, 35340472, 4889919, 42288603, 39038999, 7807946, 56698802, 6935734, 25071370, 15821461, 19395349, 85140282, 35062294],
    'val_seeds': [47916641, 34969813, 78195962, 38487519, 36264513, 73331568, 63712780, 7736212, 54362252, 66922506, 23201150, 91115034, 35872500, 95135109, 3099845, 57001532, 55211693, 88091950, 52288922, 93001253, 77132369, 12063015, 23370960, 31781082, 5888074, 81914841, 82363149, 19001235, 58768481, 63913852, 55695290, 55172316, 72809427, 77263312, 34118029, 1926022, 74453003, 76601484, 9255041, 20786080, 25999068, 27965816, 81163846, 92548770, 907694, 58868034, 27707358, 96872372, 65661879, 12269802, 55225265, 51766916, 76879830, 36346205, 16853083, 11386700, 14351009, 72074083, 19415641, 535729, 73222166, 58990977, 29204735, 17126039, 60771238, 41016746, 32321708, 71583526, 82640065, 95464371, 14922752, 65055983, 72452937, 33292732, 66959436, 19226765, 82340786, 67847309, 13671184, 70881544, 55093993, 7374361, 19658688, 69239056, 95322246, 21872275, 11668557, 75866398, 88956453, 5109167, 87775821, 75621963, 41924400, 24385116, 53302063, 26200024, 54559703, 1595941, 55785194, 40282258],
    'test_seed': 14686635,
    'train_dataset': {
        'class': LevirCdDataset,
        'args': {
            'data_root': './data/datasets/soft_links/LEVIR-CD',
            'split': 'train',
            'transforms_cfg': {
                'class': Compose,
                'args': {
                    'transforms': [(
    {
            'class': RandomCrop,
            'args': {
                'size': (256, 256),
                'resize': None,
                'interpolation': None,
            },
        },
    [('inputs', 'img_1'), ('inputs', 'img_2'), ('labels', 'change_map')]
), (
    {
            'class': RandomRotation,
            'args': {
                'choices': [0, 90, 180, 270],
            },
        },
    [('inputs', 'img_1'), ('inputs', 'img_2'), ('labels', 'change_map')]
), (
    {
            'class': Randomize,
            'args': {
                'transform': {
                    'class': Flip,
                    'args': {
                        'axis': -1,
                    },
                },
                'p': 0.5,
            },
        },
    [('inputs', 'img_1'), ('inputs', 'img_2'), ('labels', 'change_map')]
), (
    {
            'class': Randomize,
            'args': {
                'transform': {
                    'class': Flip,
                    'args': {
                        'axis': -2,
                    },
                },
                'p': 0.5,
            },
        },
    [('inputs', 'img_1'), ('inputs', 'img_2'), ('labels', 'change_map')]
), (
    {
            'class': Randomize,
            'args': {
                'transform': {
                    'class': TorchvisionWrapper,
                    'args': {
                        'transform_class': ColorJitter,
                        'brightness': 0.5,
                        'contrast': 0.5,
                        'saturation': 0.5,
                    },
                },
                'p': 0.5,
            },
        },
    ('inputs', 'img_1')
), (
    {
            'class': Randomize,
            'args': {
                'transform': {
                    'class': TorchvisionWrapper,
                    'args': {
                        'transform_class': ColorJitter,
                        'brightness': 0.5,
                        'contrast': 0.5,
                        'saturation': 0.5,
                    },
                },
                'p': 0.5,
            },
        },
    ('inputs', 'img_2')
)],
                },
            },
        },
    },
    'train_dataloader': {
        'class': DataLoader,
        'args': {
            'batch_size': 4,
            'num_workers': 4,
            'collate_fn': {
                'class': BaseCollator,
                'args': {
                    'collators': {
                        'meta_info': {
                            'image_resolution': Tensor,
                        },
                    },
                },
            },
        },
    },
    'criterion': {
        'class': SemanticSegmentationCriterion,
        'args': {
            'class_weights': (0.09177704155445099, 1.908223032951355),
        },
    },
    'val_dataset': {
        'class': LevirCdDataset,
        'args': {
            'data_root': './data/datasets/soft_links/LEVIR-CD',
            'split': 'val',
            'transforms_cfg': {
                'class': Compose,
                'args': {
                    'transforms': [(
    {
            'class': RandomCrop,
            'args': {
                'size': (256, 256),
                'resize': None,
                'interpolation': None,
            },
        },
    [('inputs', 'img_1'), ('inputs', 'img_2'), ('labels', 'change_map')]
), (
    {
            'class': RandomRotation,
            'args': {
                'choices': [0, 90, 180, 270],
            },
        },
    [('inputs', 'img_1'), ('inputs', 'img_2'), ('labels', 'change_map')]
), (
    {
            'class': Randomize,
            'args': {
                'transform': {
                    'class': Flip,
                    'args': {
                        'axis': -1,
                    },
                },
                'p': 0.5,
            },
        },
    [('inputs', 'img_1'), ('inputs', 'img_2'), ('labels', 'change_map')]
), (
    {
            'class': Randomize,
            'args': {
                'transform': {
                    'class': Flip,
                    'args': {
                        'axis': -2,
                    },
                },
                'p': 0.5,
            },
        },
    [('inputs', 'img_1'), ('inputs', 'img_2'), ('labels', 'change_map')]
), (
    {
            'class': Randomize,
            'args': {
                'transform': {
                    'class': TorchvisionWrapper,
                    'args': {
                        'transform_class': ColorJitter,
                        'brightness': 0.5,
                        'contrast': 0.5,
                        'saturation': 0.5,
                    },
                },
                'p': 0.5,
            },
        },
    ('inputs', 'img_1')
), (
    {
            'class': Randomize,
            'args': {
                'transform': {
                    'class': TorchvisionWrapper,
                    'args': {
                        'transform_class': ColorJitter,
                        'brightness': 0.5,
                        'contrast': 0.5,
                        'saturation': 0.5,
                    },
                },
                'p': 0.5,
            },
        },
    ('inputs', 'img_2')
)],
                },
            },
        },
    },
    'val_dataloader': {
        'class': DataLoader,
        'args': {
            'batch_size': 1,
            'num_workers': 4,
            'collate_fn': {
                'class': BaseCollator,
                'args': {
                    'collators': {
                        'meta_info': {
                            'image_resolution': Tensor,
                        },
                    },
                },
            },
        },
    },
    'test_dataset': {
        'class': LevirCdDataset,
        'args': {
            'data_root': './data/datasets/soft_links/LEVIR-CD',
            'split': 'test',
            'transforms_cfg': {
                'class': Compose,
                'args': {
                    'transforms': [(
    {
            'class': RandomCrop,
            'args': {
                'size': (224, 224),
                'resize': None,
                'interpolation': None,
            },
        },
    [('inputs', 'img_1'), ('inputs', 'img_2'), ('labels', 'change_map')]
)],
                },
            },
        },
    },
    'test_dataloader': {
        'class': DataLoader,
        'args': {
            'batch_size': 1,
            'num_workers': 4,
            'collate_fn': {
                'class': BaseCollator,
                'args': {
                    'collators': {
                        'meta_info': {
                            'image_resolution': Tensor,
                        },
                    },
                },
            },
        },
    },
    'metric': {
        'class': SemanticSegmentationMetric,
        'args': {
            'num_classes': 2,
        },
    },
    'model': {
        'class': Changer,
        'args': {
            'encoder_cfg': {
                'class': IA_MixVisionTransformer,
                'args': {
                    'in_channels': 3,
                    'embed_dims': 64,
                    'num_stages': 4,
                    'num_layers': [2, 2, 2, 2],
                    'num_heads': [1, 2, 5, 8],
                    'patch_sizes': [7, 3, 3, 3],
                    'sr_ratios': [8, 4, 2, 1],
                    'out_indices': (0, 1, 2, 3),
                    'mlp_ratio': 4,
                    'qkv_bias': True,
                    'drop_rate': 0.0,
                    'attn_drop_rate': 0.0,
                    'drop_path_rate': 0.1,
                    'pretrained': './models/change_detection/changer/checkpoints/mit_b1.pth',
                    'interaction_cfg': (
                        None,
                        {
                                                    'class': SpatialExchange,
                                                    'args': {
                                                        'p': 0.5,
                                                    },
                                                },
                        {
                                                    'class': ChannelExchange,
                                                    'args': {
                                                        'p': 0.5,
                                                    },
                                                },
                        {
                                                    'class': ChannelExchange,
                                                    'args': {
                                                        'p': 0.5,
                                                    },
                                                }
                    ),
                },
            },
            'decoder_cfg': {
                'class': ChangerDecoder,
                'args': {
                    'in_index': [0, 1, 2, 3],
                    'dropout_ratio': 0.1,
                    'num_classes': 2,
                    'norm_cfg': {
                        'type': 'SyncBN',
                        'requires_grad': True,
                    },
                    'align_corners': False,
                    'sampler': {
                        'type': 'mmseg.OHEMPixelSampler',
                        'thresh': 0.7,
                        'min_kept': 100000,
                    },
                    'in_channels': [64, 128, 320, 512],
                    'channels': 128,
                },
            },
        },
    },
    'optimizer': {
        'class': SingleTaskOptimizer,
        'args': {
            'optimizer_config': {
                'class': SGD,
                'args': {
                    'lr': 0.001,
                    'momentum': 0.9,
                    'weight_decay': 0.0001,
                },
            },
        },
    },
    'scheduler': {
        'class': PolynomialLR,
        'args': {
            'optimizer': None,
            'total_iters': None,
            'power': 0.9,
        },
    },
}
