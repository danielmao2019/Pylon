# This file is automatically generated by `./configs/benchmarks/change_detection/gen_bi_temporal.py`.
# Please do not attempt to modify manually.
from torch import Tensor
from torch.optim.lr_scheduler import PolynomialLR
from torch.optim.sgd import SGD
from torch.utils.data.dataloader import DataLoader
from torchvision.transforms.transforms import ColorJitter
from criteria.vision_2d.dense_prediction.dense_classification.semantic_segmentation import SemanticSegmentationCriterion
from data.collators.base_collator import BaseCollator
from data.datasets.change_detection_datasets.bi_temporal.cdd_dataset import CDDDataset
from data.transforms.compose import Compose
from data.transforms.randomize import Randomize
from data.transforms.torchvision_wrapper import TorchvisionWrapper
from data.transforms.vision_2d.crop.random_crop import RandomCrop
from data.transforms.vision_2d.flip import Flip
from data.transforms.vision_2d.random_rotation import RandomRotation
from metrics.vision_2d.semantic_segmentation_metric import SemanticSegmentationMetric
from models.change_detection.changer.changer_model import Changer
from models.change_detection.changer.modules.changer_decoder import ChangerDecoder
from models.change_detection.changer.modules.interaction_layer import ChannelExchange, SpatialExchange
from models.change_detection.changer.modules.interaction_mit import IA_MixVisionTransformer
from optimizers.single_task_optimizer import SingleTaskOptimizer
from runners.supervised_single_task_trainer import SupervisedSingleTaskTrainer


config = {
    'runner': SupervisedSingleTaskTrainer,
    'work_dir': './logs/benchmarks/change_detection/cdd/Changer-mit-b0_run_0',
    'epochs': 100,
    'init_seed': 58471565,
    'train_seeds': [55669956, 66069247, 79521129, 13143639, 54450693, 5448984, 98492430, 83376984, 97731698, 39831326, 23178355, 80456121, 22336659, 60757269, 35063505, 34221815, 123972, 14835219, 66693876, 78594479, 53823331, 72017286, 1502371, 78650494, 29583850, 84289919, 13315634, 89210071, 82591812, 32200814, 60066982, 19144367, 81998636, 42999931, 70999004, 77910404, 49921937, 69242023, 82995060, 37919883, 75554233, 94583976, 55923338, 84675329, 83760357, 16767403, 8924593, 97039894, 18196781, 56461203, 80061658, 38043149, 67137959, 75485253, 12332270, 66796491, 30845956, 98692744, 43194319, 47951666, 47975485, 44799842, 75153366, 58135037, 17258537, 35600796, 67048001, 11828567, 39679698, 92186897, 952855, 23544470, 73495380, 7491351, 13211093, 13064431, 70762088, 64383885, 61575081, 14350937, 61530136, 94050530, 36884290, 60899466, 97404018, 19231075, 33385330, 61326331, 50440745, 94097491, 9517583, 15528440, 3859684, 20959605, 9747600, 49846225, 71806847, 86634, 727284, 78441107],
    'val_seeds': [66164978, 93241742, 31498048, 56427087, 77364455, 79640830, 65640875, 29222259, 46434428, 6032484, 28279893, 46388266, 24554052, 46052173, 65124987, 75601352, 1391676, 83179004, 29825770, 76206391, 763967, 48054996, 28260394, 98984506, 66572059, 44006353, 45354256, 1267637, 59527957, 2370431, 27308480, 83543563, 42648190, 85708999, 31870293, 10200000, 87808425, 85209802, 47720764, 68364619, 82168996, 75083233, 11834078, 39737191, 7290594, 60830674, 5982871, 95250997, 34426330, 58515374, 33003961, 90724360, 44200387, 88742292, 49063822, 91167302, 34341619, 71945958, 56959007, 24039114, 82952207, 60008146, 11878297, 61139693, 74327872, 33301883, 22059835, 87551461, 71468364, 44029482, 89050899, 65894795, 66140219, 83650367, 57656743, 2801373, 59300357, 93487220, 87040575, 25893025, 64962257, 76544305, 36304863, 1628145, 3949201, 28153748, 34518953, 71091918, 66971729, 44972615, 29851992, 53672809, 8306934, 35981288, 71815236, 19166436, 41718054, 52101834, 32048673, 70308643],
    'test_seed': 98537480,
    'train_dataset': {
        'class': CDDDataset,
        'args': {
            'data_root': './data/datasets/soft_links/CDD',
            'split': 'train',
            'transforms_cfg': {
                'class': Compose,
                'args': {
                    'transforms': [(
    {
            'class': RandomCrop,
            'args': {
                'size': (256, 256),
                'resize': None,
                'interpolation': None,
            },
        },
    [('inputs', 'img_1'), ('inputs', 'img_2'), ('labels', 'change_map')]
), (
    {
            'class': RandomRotation,
            'args': {
                'choices': [0, 90, 180, 270],
            },
        },
    [('inputs', 'img_1'), ('inputs', 'img_2'), ('labels', 'change_map')]
), (
    {
            'class': Randomize,
            'args': {
                'transform': {
                    'class': Flip,
                    'args': {
                        'axis': -1,
                    },
                },
                'p': 0.5,
            },
        },
    [('inputs', 'img_1'), ('inputs', 'img_2'), ('labels', 'change_map')]
), (
    {
            'class': Randomize,
            'args': {
                'transform': {
                    'class': Flip,
                    'args': {
                        'axis': -2,
                    },
                },
                'p': 0.5,
            },
        },
    [('inputs', 'img_1'), ('inputs', 'img_2'), ('labels', 'change_map')]
), (
    {
            'class': Randomize,
            'args': {
                'transform': {
                    'class': TorchvisionWrapper,
                    'args': {
                        'transform_class': ColorJitter,
                        'brightness': 0.5,
                        'contrast': 0.5,
                        'saturation': 0.5,
                    },
                },
                'p': 0.5,
            },
        },
    ('inputs', 'img_1')
), (
    {
            'class': Randomize,
            'args': {
                'transform': {
                    'class': TorchvisionWrapper,
                    'args': {
                        'transform_class': ColorJitter,
                        'brightness': 0.5,
                        'contrast': 0.5,
                        'saturation': 0.5,
                    },
                },
                'p': 0.5,
            },
        },
    ('inputs', 'img_2')
)],
                },
            },
        },
    },
    'train_dataloader': {
        'class': DataLoader,
        'args': {
            'batch_size': 4,
            'num_workers': 4,
            'collate_fn': {
                'class': BaseCollator,
                'args': {
                    'collators': {
                        'meta_info': {
                            'image_resolution': Tensor,
                        },
                    },
                },
            },
        },
    },
    'criterion': {
        'class': SemanticSegmentationCriterion,
        'args': {
            'class_weights': (0.1918177604675293, 1.8081822395324707),
        },
    },
    'val_dataset': {
        'class': CDDDataset,
        'args': {
            'data_root': './data/datasets/soft_links/CDD',
            'split': 'val',
            'transforms_cfg': {
                'class': Compose,
                'args': {
                    'transforms': [(
    {
            'class': RandomCrop,
            'args': {
                'size': (256, 256),
                'resize': None,
                'interpolation': None,
            },
        },
    [('inputs', 'img_1'), ('inputs', 'img_2'), ('labels', 'change_map')]
), (
    {
            'class': RandomRotation,
            'args': {
                'choices': [0, 90, 180, 270],
            },
        },
    [('inputs', 'img_1'), ('inputs', 'img_2'), ('labels', 'change_map')]
), (
    {
            'class': Randomize,
            'args': {
                'transform': {
                    'class': Flip,
                    'args': {
                        'axis': -1,
                    },
                },
                'p': 0.5,
            },
        },
    [('inputs', 'img_1'), ('inputs', 'img_2'), ('labels', 'change_map')]
), (
    {
            'class': Randomize,
            'args': {
                'transform': {
                    'class': Flip,
                    'args': {
                        'axis': -2,
                    },
                },
                'p': 0.5,
            },
        },
    [('inputs', 'img_1'), ('inputs', 'img_2'), ('labels', 'change_map')]
), (
    {
            'class': Randomize,
            'args': {
                'transform': {
                    'class': TorchvisionWrapper,
                    'args': {
                        'transform_class': ColorJitter,
                        'brightness': 0.5,
                        'contrast': 0.5,
                        'saturation': 0.5,
                    },
                },
                'p': 0.5,
            },
        },
    ('inputs', 'img_1')
), (
    {
            'class': Randomize,
            'args': {
                'transform': {
                    'class': TorchvisionWrapper,
                    'args': {
                        'transform_class': ColorJitter,
                        'brightness': 0.5,
                        'contrast': 0.5,
                        'saturation': 0.5,
                    },
                },
                'p': 0.5,
            },
        },
    ('inputs', 'img_2')
)],
                },
            },
        },
    },
    'val_dataloader': {
        'class': DataLoader,
        'args': {
            'batch_size': 1,
            'num_workers': 4,
            'collate_fn': {
                'class': BaseCollator,
                'args': {
                    'collators': {
                        'meta_info': {
                            'image_resolution': Tensor,
                        },
                    },
                },
            },
        },
    },
    'test_dataset': {
        'class': CDDDataset,
        'args': {
            'data_root': './data/datasets/soft_links/CDD',
            'split': 'test',
            'transforms_cfg': {
                'class': Compose,
                'args': {
                    'transforms': [(
    {
            'class': RandomCrop,
            'args': {
                'size': (224, 224),
                'resize': None,
                'interpolation': None,
            },
        },
    [('inputs', 'img_1'), ('inputs', 'img_2'), ('labels', 'change_map')]
)],
                },
            },
        },
    },
    'test_dataloader': {
        'class': DataLoader,
        'args': {
            'batch_size': 1,
            'num_workers': 4,
            'collate_fn': {
                'class': BaseCollator,
                'args': {
                    'collators': {
                        'meta_info': {
                            'image_resolution': Tensor,
                        },
                    },
                },
            },
        },
    },
    'metric': {
        'class': SemanticSegmentationMetric,
        'args': {
            'num_classes': 2,
        },
    },
    'model': {
        'class': Changer,
        'args': {
            'encoder_cfg': {
                'class': IA_MixVisionTransformer,
                'args': {
                    'in_channels': 3,
                    'embed_dims': 32,
                    'num_stages': 4,
                    'num_layers': [2, 2, 2, 2],
                    'num_heads': [1, 2, 5, 8],
                    'patch_sizes': [7, 3, 3, 3],
                    'sr_ratios': [8, 4, 2, 1],
                    'out_indices': (0, 1, 2, 3),
                    'mlp_ratio': 4,
                    'qkv_bias': True,
                    'drop_rate': 0.0,
                    'attn_drop_rate': 0.0,
                    'drop_path_rate': 0.1,
                    'pretrained': './models/change_detection/changer/checkpoints/mit_b0.pth',
                    'interaction_cfg': (
                        None,
                        {
                                                    'class': SpatialExchange,
                                                    'args': {
                                                        'p': 0.5,
                                                    },
                                                },
                        {
                                                    'class': ChannelExchange,
                                                    'args': {
                                                        'p': 0.5,
                                                    },
                                                },
                        {
                                                    'class': ChannelExchange,
                                                    'args': {
                                                        'p': 0.5,
                                                    },
                                                }
                    ),
                },
            },
            'decoder_cfg': {
                'class': ChangerDecoder,
                'args': {
                    'in_index': [0, 1, 2, 3],
                    'dropout_ratio': 0.1,
                    'num_classes': 2,
                    'norm_cfg': {
                        'type': 'SyncBN',
                        'requires_grad': True,
                    },
                    'align_corners': False,
                    'sampler': {
                        'type': 'mmseg.OHEMPixelSampler',
                        'thresh': 0.7,
                        'min_kept': 100000,
                    },
                    'in_channels': [32, 64, 160, 256],
                    'channels': 128,
                },
            },
        },
    },
    'optimizer': {
        'class': SingleTaskOptimizer,
        'args': {
            'optimizer_config': {
                'class': SGD,
                'args': {
                    'lr': 0.001,
                    'momentum': 0.9,
                    'weight_decay': 0.0001,
                },
            },
        },
    },
    'scheduler': {
        'class': PolynomialLR,
        'args': {
            'optimizer': None,
            'total_iters': None,
            'power': 0.9,
        },
    },
}
